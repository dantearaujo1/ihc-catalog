{
    "complete_detailed_list": [
        {
            "ux_instruments": "2DES",
            "reference": "Schubert, E. (1999). Measuring emotion continuously: Validity and reliability of the two-dimensional emotion-space. Australian Journal of Psychology, 51(3), 154-165.",
            "year": "1999",
            "type_of_instrument": "Others (scale and two-dimensional diagram/ graph area)",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "Happy - Sad / Aroused - Sleepy",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "It is a computer-controlled instrument that measures direct, self-reported emotion expressed by stimuli along two bipolar dimensions: happy/sad valence (VA) and aroused/sleepy (AR)",
            "general_procedure": "The 2DES consists of a square with the dimensions aligned. The human-computer interface software records cursor movements within this square on a 201-by-201 point scale ranging from -100 to +I00 for each dimension as a musical example unfolds. as perpendicular axes: valence as the x axis and arousal as the y axis. The arousal dimension was reinforced by the size of mouth and eye opening, and the valence dimension by concavity of mouth."
        },
        {
            "ux_instruments": "Expressing Experiences and Emotions (3E)",
            "reference": "Tahti, M., Arhippainen, L., 2004. A Proposal of collecting Emotions and Experiences. Volume 2 in Interactive Experiences in HCI, pp. 195–198.",
            "year": "2004",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Qualitative",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "3E is a self report method, in which the user is provided with a simple pictorial template for expressing emotions and experience, in the form of a sketched human body. The user is able to draw a face to the human figure so projecting her/his emotional state to the figure. In a later version of the method, the human figure was added with two cartoon-like speech bubbles",
            "general_procedure": "The user will express emotion and experience in the form of a sketched human body, by drawing a face to the human figure provided by the instrument, projecting her/his emotional state to the figure. This human figure has with it two cartoon-like speech bubbles: the cloud-like one is used to sepict inner thoughts (pictorial or verbal) and the square-like is for oral expression."
        },
        {
            "ux_instruments": "Expressing Experiences and Emotions* (3E*)",
            "reference": "Ferreira, Bruna Moraes, et al. \"Evaluation of UX Methods: Lessons Learned When Evaluating a Multi-user Mobile Application.\" International Conference on Human-Computer Interaction. Springer, Cham, 2016.",
            "year": "2016",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Qualitative",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "Modified 3E method to allow a more in-depth evaluation of different activities in the application.  Bubbles were also added, so the user describes his/her thoughts and opinions regarding the application.",
            "general_procedure": "Using the original 3E method, a subject can only describe a general view of the application’s use. The modification allows a subject to describe his/her experiences for each performed activity. In this modification, the method is applied for each of the tasks performed by the subjects. "
        },
        {
            "ux_instruments": "Aesthetics Scale",
            "reference": "Talia Laviea and Noam Tractinsky, Assessing dimensions of perceived visual aesthetics of web sites, International Journal of Human-Computer Studies, Volume 60, Issue 3, March 2004, Pages 269-298",
            "year": "2004",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Online Plataform",
            "ux-quality": "Aesthetics",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "To address the lack of appropriate concepts and measures of aesthetics, a measurement instrument of perceived web site aesthetics was develop. Using exploratory and confirmatory factor analyses, the researchers found that \"users' perceptions consist of two main dimensions, which we termed 'classical aesthetics' and 'expressive aesthetics' (...) Each of the aesthetic dimensions is measured by a five item scale\".",
            "general_procedure": "Paper description of the procedure: the participants visited an site and performed a task. Upon completion of the task, they answered the questionnaire, which aims to understand the user's perceptions about aesthetics in two dimensions (\"classical aesthetics\" and \"expressive aesthetics\"). Each one is measured by a 7-point scale ranging from (1) ‘‘strongly disagree’’ to (7) ‘‘strongly agree’’."
        },
        {
            "ux_instruments": "AFFDEX Software Development Kit (AFFDEX SDK)",
            "reference": "McDuff, D., Mahmoud, A., Mavadati, M., Amr, M., Turcot, J., & Kaliouby, R. el. (2016). AFFDEX SDK. Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA ’16. doi:10.1145/2851581.2890247",
            "year": "2016",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "\"A real-time facial expression recognition of toolkit that can automatically code the expressions of multiple people simultaneously. The system is trained on  the world's largest dataset of facial expressions and has been optimized to operate on mobile devices and with very few false detections. The toolkit offers the potential for the design of novel interfaces that respond to user's emotional states based on their facial expressions. The Software Development Kit (SDK) allow easy integration of the software into other applications.\"",
            "general_procedure": "The system for automated facial coding has four main components: 1) Face and facial landmark detection, 2) face texture feature extraction, 3) facial action classification and 4) emotion expression modelling. Face detection is performed using the Viola-Jones face detection algorithm. Landmark detection is then applied to each facil bounding box and 34 landmarks identified. If the confidence of the landmark detection is below a threshold then the bounding box is ignored. The facial landmarks, head pose and intraocular distance for each face are exposed in the SDK.  Histogram of Oriented Gradient (HOG) are extracted from the image region of interest defined by the facial landmark points. Support Vector Machine (SVM) classifiers, trained on 10,000s of manually coded facial images collected from around the world, are used to provide scores from 0 to 100 for  each facial action. The emotion expressions (Anger, Disgust, Fear, Joy, Sadness, Surprise and Contempt) are based on combinations of facial actions. This coding was built on the EMFACS emotional facial action coding system. The emotion expressions are given a similar score from 0 (absent) to 100 (present). In addition to facial action and emotion expression classifiers the SDK has classifiers for determining gender and whether the person is wearing glasses. The classifiers have two operating modes: static and causal. The static classifiers allow classification of single images. The causal classifiers leverage temporal information available in video sequences to further increase the accuracy of the facial expression measures."
        },
        {
            "ux_instruments": "Affect Grid",
            "reference": "Russell, J. A., Weiss, A., & Mendelsohn, G. A. (1989). Affect grid: A single-item scale of pleasure and arousal. Journal of Personality and Social Psychology, 57, 493–502",
            "year": "1989",
            "type_of_instrument": "Others (scale and two-dimensional diagram/ graph area)",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "Pleasure - Displeasure / Arousal - Sleepiness",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A single-item scale, designed for assessing affect along the dimensions of pleasure-displeasure and arousal-sleepiness.",
            "general_procedure": "The subject places one checkmark somewhere in the 9x9 grid. The pleasure-displeasure (P) score is taken as the number of the square checked, with squares numbered along the horizontal dimension, counting 1 to 9 starting at the left. The arousal-sleepiness (A) score is taken as the number of the square checked, with squares numbered along the vertical dimension, counting 1 to 9 starting at the bottom"
        },
        {
            "ux_instruments": "AFFECTAURA",
            "reference": "McDuff, D., Karlson, A., Kapoor, A., Roseway, A., & Czerwinski, M. (2012). AffectAura. Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems - CHI ’12. doi:10.1145/2207676.2208525",
            "year": "2012",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "Valence, arousal and engagement",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "An emotional prosthetic that allows users to reflect on their emotional states over long periods of time. A multimodal sensor set-up for continuous logging of audio, visual, physiological and contextual data, a classification scheme for predicting user affective state and an interface for user reflection. The system continuously predicts a user's valence, arousal and engagement, and correlates this with information on events, communications and data interactions",
            "general_procedure": "AffectAura consists of an 'affect timeline' capturing the ebb and flow of affect represented by a series of bubbles. The user can drill down by hovering over a bubble to reveal a detailed breakdown of their activities and interactions associated with that time. It is displayed daily and hourly granularities of data for the user, to simplify the visualization. Each ―page‖ shows one day divided into hour intervals. "
        },
        {
            "ux_instruments": "AffectButton",
            "reference": "Broekens, Joost, and Willem-Paul Brinkman. \"AffectButton: A method for reliable and valid affective self-report.\" International Journal of Human-Computer Studies 71.6 (2013): 641-667.",
            "year": "2013",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "(1) Pleasure (valence), (2) arousal and (3) dominance.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The AffectButton is a button that enables users to provide affective feedback in terms of values on the well-known three affective dimensions of pleasure (valence), arousal and dominance.",
            "general_procedure": "The AffectButton is an interface component that functions and looks like a medium-sized button. The button presents one dynamically changing iconic facial expression that changes based on the coordinates of the user’s pointer in the button. To give affective feedback the user selects the most appropriate expression by clicking the button, effectively enabling 1-click affective self-report on 3 affective dimension"
        },
        {
            "ux_instruments": "AffectCam",
            "reference": "Sas, C., Fratczak, T., Rees, M., Gellersen, H., Kalnikaite, V., Coman, A., & Höök, K. (2013). AffectCam. CHI ’13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA ’13. doi:10.1145/2468356.2468542",
            "year": "2013",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "Arousal ",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "AffectCam is a wearable system integrating SenseCam and BodyMedia SenseWear for capturing galvanic skin response as a measure of bodily arousal. AffectCam’s algorithms use arousal as a filtering mechanism for selecting the most personally relevant photos captured during people’s ordinary daily life, i.e. high arousal photos. ",
            "general_procedure": "AffectCam system integrates two commercial wearable systems, i.e. SenseCam and BodyMedia SenseWear. SenseWear has been used to monitor emotional arousal in various HCI applications for stress management. AffectCam includes algorithms for multi-sensor data integration. A XML parser decomposes the SenseWear data file and retrieves the GSR readings, which are converted into vectors and stored in an object instance of the Java program. A simple algorithm was developed to parse the creation dates of photos taken by the SenseCam, and search the time stamps of the corresponding vector of the GSR readings from the SenseWear. For identifying the peaks of emotional arousal, another algorithm finds sequences of consecutive GSR readings where each value is higher than its predecessor, and creates a peak object consisting of start and end times of the peak, its height, differences between readings and score. The latter is computed by dividing the overall relative height of the peak by the number of readings in the sequence. The interface consists of two views for choosing recorded sessions and photo viewing that allows for browsing all photos within the data file.  Users could cycle through them and make annotations on the current photo."
        },
        {
            "ux_instruments": "Affective Diary",
            "reference": "Stahl, A., Hook, K., Svensson, M., Taylor, A.S., and Combetto, M.: Experiencing the Affective Diary. Personal and Ubiquitous Computing, 13(5) 2009, 365-378.",
            "year": "2009",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "Psycho-physiological measurements are taken as part of a field study, and combined with activity data plus user's own comments on the recorded events.",
            "general_procedure": "During a field study, a participant wears a sensor that registers their physical states. User's mobile phone logs the activities on the phone. The data from both sources is combined to scraps of person's life. The scraps data is presented to the participant who can scribble their reflected thoughts on them."
        },
        {
            "ux_instruments": "All The Feels",
            "reference": "Robinson, Raquel Breejon. All the Feels: A Twitch Overlay that Displays Streamers’ Biometrics to Spectators. Diss. UC Santa Cruz, 2018.",
            "year": "2018",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quantitative",
            "application_domain": "Audiovisual",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "All The Feels explores the potential value of introducing additional information to viewers about the player's emotional state, including a Heads-Up Device (HUD) that provides real-time facial detection and biometric information, expanding previous preliminary work",
            "general_procedure": "The streamer plays a game and makes a broadcast, with the ATF (All the Feels) configured. The live stream is recorded on video and saved for later analysis."
        },
        {
            "ux_instruments": "Attrak-Work questionnaire",
            "reference": "Väätäjä, H., Koponen, T., & Roto, V. (2009). Developing practical tools for user experience evaluation: a case from mobile news journalism. In European Conference on Cognitive Ergonomics: Designing beyond the Product—Understanding Activity and User Experience in Ubiquitous Environments (p. 23).",
            "year": "2009",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Mobile",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "Jornalists",
            "framework": "Human/user focus",
            "main_ideia": "An instrument to support the evaluation of user experience of mobile systems in the context of mobile news journalism. The presented questionnaire assesses user’s perception of the pragmatic (usability and task and goal achievement) and hedonic (stimulation and identification) qualities and an overall judgment of appeal.  The Hassenzahl’s model was the starting point in the development of the questionnaire",
            "general_procedure": "There are five attribute groups used as scales. They are: 1. Pragmatic quality – Usability; 2. Task and goal achievement; 3. Hedonic quality – Stimulation; 4. Hedonic quality – Identification and 5. Appeal. The scale can be filled in right after the participant has used the system, for example, a field study session"
        },
        {
            "ux_instruments": "AttrakDiff",
            "reference": "Hassenzahl, M., Burmester, M., & Koller, F. (2003). AttrakDiff: Ein Fragebogen zur Messung wahrgenommener hedonischer und pragmatischer Qualitat [AttracDiff: A questionnaire to measure perceived hedonic and pragmatic quality]. In J. Ziegler & G. Szwillus (Eds.), Mensch&Computer 2003. Interaktion in Bewegung (pp. 187–196). Stuttgart, Leipzig: B. G. Teubner.",
            "year": "2003",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Hedonic and Pragmatic",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "User/artifact/environment relations",
            "main_ideia": "AttrakDiff enables the evaluation of interactive products in terms of their pragmatic and hedonic quality. It consists of 23 seven-level items whose endpoints are each formed by an opposite adjective (e.g., \"confusing - clear\", \"extraordinary - common\", \"Good Bad\"). In each case several items are combined into one scale. The mean the item represents the scale value for pragmatic quality (PQ), hedonic quality (HQ) and Attractiveness (ATT). The two studies showed that hedonic and pragmatic qualities are consistent and independently perceived qualities. ",
            "general_procedure": "There are items arranged on a 7-point scale. The end points of the scale are formed by opposing adjectives. The average of the items forms the value for Pragmatic Quality, Hedonic Quality and Attractiveness."
        },
        {
            "ux_instruments": "Core Elements of the Gaming Experience Questionnaire (CEGEQ)",
            "reference": "Calvillo-Gámez, Eduardo H., Paul Cairns, and Anna L. Cox. \"Assessing the core elements of the gaming experience.\" Game user experience evaluation. Springer, Cham, 2015. 37-62.",
            "year": "2015",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "CEGE, Video-game, Puppetry, Game-play, Environment, Control, Ownership and Facilitators.",
            "target_users_": "all types of users",
            "framework": "User/artifact/environment relations",
            "main_ideia": "The CEGE Questionnaire (CEGEQ) was developed to measure the observable variables in order to understand the behaviour of the latent constructs. The questionnaire is created with 38 items and 10 scales. The scales are Enjoyment, Frustration, CEGE, Puppetry, Video-game, Control, Facilitators, Ownership, Game-play and Environment. The first two scales were included as a reference to see the elationships between CEGE and Enjoyment and Frustration.",
            "general_procedure": "Paper example of using the questionnaire: participants were recruited and carried out the experiment individually. They started the experiment with a briefing of the experiment, verbally and written, after which they were asked to sign a consent form and complete the general survey form. Participants were asked to try out to forget they were in a lab and think they were in the place where they usually engaged with video-games. Each participant was given an explanation of how to play the game with each device. Participants would play for approximately 15 min and then they would complete the questionnaire. The CEGEQ has 38 items with a 7-point Likert scale. "
        },
        {
            "ux_instruments": "Consumer Videogame Engagement",
            "reference": "Abbasi, Amir Zaib, Ding Hooi Ting, and Helmut Hlavacs. \"Engagement in games: Developing an instrument to measure consumer videogame engagement and its validation.\" International Journal of Computer Games Technology 2017 (2017).",
            "year": "2017",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Engagement",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A scale that had both psycho-logical (cognitive and affective) and behavioral dimensions",
            "general_procedure": "Experiment reported in the article: this study collected data from adolescent students and analyzed the data through internal consistency analysis and exploratory factor analysis. This study applied a multiple-stage sampling technique to collect the study subjects. During data collection, the study questionnaire was distributed and collected in the classroom under the presence of a teacher."
        },
        {
            "ux_instruments": "Creativity Scale ",
            "reference": "Horn, Diana, and G. Salvendy. \"Product creativity: conceptual model, measurement and characteristics.\" Theoretical Issues in Ergonomics Science 7.4 (2006): 395-412.",
            "year": "2006",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Product Creativity",
            "sub_qualities_or_valence": "Novelty, Resolution, Emotion, Centrality, Importance and Desire",
            "target_users_": "Consumers",
            "framework": "Product/artifact focus",
            "main_ideia": "A questionnaire to measure consumer perception of product creativity.",
            "general_procedure": "Experiment reported in the article: A paper research, including all items of the proposed instrument, was delivered to the students. Participants were invited to fill out the questionnaire based on their previous experience with creative products."
        },
        {
            "ux_instruments": "Day Reconstruction Method",
            "reference": "KAHNEMAN, Daniel et al. A survey method for characterizing daily life experience: The day reconstruction method. Science, v. 306, n. 5702, p. 1776-1780, 2004.",
            "year": "2004",
            "type_of_instrument": "Others (diary template)",
            "type_of_approach": "Qualitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "DRM respondents first revive memories of the previous day by constructing a diary consisting of a sequence of episodes. Then they describe each episode by answering questions about the situation and about the feelings that they experienced, as in experience sampling. The goal is to provide an accurate picture of the experience associated with activities.",
            "general_procedure": "Respondents first answer demographic and general satisfaction questions. Next, they are asked to construct a short diary of the previous day. Indications of the end of an episode might be going to a different location, ending one activity and starting another, or a change in the people you are interacting with"
        },
        {
            "ux_instruments": "Differential Emotions Scale (DES)",
            "reference": "Boyle, G. J. (1984). Reliability and validity of Izard's differential emotions scale. Personality and Individual Differences, 5(6), 747-750.",
            "year": "1984",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The DES is purported to measure the subjective-experience component of the fundamental emotions, each of which was defined theoretically as having neural, neuromuscular-expressive, and experiential components. The most recent version of this mood-state inventory, the DES-IV, is comprised of 49 items purported to measure 12 basic emotions (namely, Interest, Joy, Surprise, Sadness, Anger, Disgust, Contempt, Hostility, Fear, Shame, Shyness, and Guilt)",
            "general_procedure": "The DES instructions ask the respondents to consider the experience they described and to rate how often s/he experienced each emotion item during the experience. The DES is formulated around a thirty-item adjective checklist, with three adjectives of each of the ten emotions that are considered to be fundamental by Izard (1992): joy,surprise, anger, disgust, contempt, shame, guilt, fear, interest, and sadness. Each item is administered on a 5-point (never to very often) scale."
        },
        {
            "ux_instruments": "Dispositional Flow Scale-2",
            "reference": "Jackson, Susan A., and Robert C. Eklund. \"Assessing flow in physical activity: The flow state scale–2 and dispositional flow scale–2.\" Journal of Sport and Exercise Psychology 24.2 (2002): 133-150.",
            "year": "2002",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Flow",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "Self-report instrument designed to evaluate flow experiences in physical activity.",
            "general_procedure": "Participants were recruited into college classes, sports teams and events such as triathlons. A standard introduction and instructions were given to all participants, and consent procedures were followed. Dispositional measures were completed at a time separated from the participation of participants in physical activity. The Flow State Scale was given to respondents to complete after participating in their core activity."
        },
        {
            "ux_instruments": "EIDOS Metrics Suite",
            "reference": "Drachen, A., & Canossa, A. (2009). Analyzing spatial user behavior in computer games using geographic information systems. Proceedings of the 13th International MindTrek Conference: Everyday Life in the Ubiquitous Era on - MindTrek ’09. doi:10.1145/1621841.1621875",
            "year": "2009",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "User/artifact/environment relations",
            "main_ideia": "The EIDOS Metrics Suite, a system that permits the tracking, capturing, storage and reporting of game metrics, customized to the different games produced at the EIDOS studios; was developed by IO Interactive and is maintained by the EIDOS Online Development Team, as a response to the requirement of understanding the details of interaction between players and game, and to be able to monitor and analyze player behavior over extended periods of time",
            "general_procedure": "Data is captured from testers (users) to a central SQL EIDOS server, from where they are drawn in different software analysis packages such as SPSS or ArcGIS for cleaning, evaluation and analysis. The data is then exported to the visualization software, and a report developed for the target user (eg designer, QA)."
        },
        {
            "ux_instruments": "Emocards",
            "reference": "Desmet, P.M.A., Overbeeke, C.J. & Tax, S. J. E. T. (2001). Designing Products with Added Emotional Value: Development and Application of an Approach for Research through Design. The Design Journal, 4(1), 32-47",
            "year": "2001",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Qualitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The emocards are based on the dimensions ‘pleasantness’ and ‘arousal’. Based on the two dimensions, Russell created a ‘circumplex of emotions’. The facial expressions of the 16 emocards represent eight distinct places on the circumplex. Each octant of the circumplex is represented by both a male and a female face. In an experiment, subjects can express their emotional responses to products by pointing out the card that best indicates their response. It works like a starting point for the communication between the designer and the users",
            "general_procedure": "At the end of every task / time duration, ask the person to pick one of several cartoon faces that identifies how they are feeling about their interaction."
        },
        {
            "ux_instruments": "Emoji UX Questionnaire",
            "reference": "ALISMAIL, Sarah; ZHANG, Hengwei. The Use of Emoji in Electronic User Experience Questionnaire: An Exploratory Case Study. 2018.",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Mobile devices",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "-",
            "main_ideia": "It is a five point-scale with 22 items, made with emojis.  Emojis are organized on a single scale representing both positive and negative reactions. ",
            "general_procedure": "The user must  assess the Mobile application selecting an emoji per line."
        },
        {
            "ux_instruments": "Emoscope - EMOTRACKER",
            "reference": "Lasa, G., Justel, D., Gonzalez, I., Iriarte, I., & Val, E. (2017). Next generation of tools for industry to evaluate the user emotional perception: the biometric-based multimethod tools. The Design Journal, 20(sup1), S2771–S2777. doi:10.1080/14606925.2017.1352788",
            "year": "2007",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The Emotracker collects data from the Eye Tracking. The output of files is versatile and configurable, but those of common use are: a file of video with the tour of the eye, the points of attention on the interface, a thermal map where the areas the user has looked to are distinguished through different colours and intensity.",
            "general_procedure": "Data from the Emotron and Emotracking, associated to the data from user, time and task, is analyzed together with the images of the module of capture of the facial expression of the user during the interaction. In this way, we associate the emotional labels to the facial expression and the protocol of thinking aloud in that precise moment, as well as data of pupillometry and thermal areas in screen."
        },
        {
            "ux_instruments": "Emoscope - EMOTRON",
            "reference": "Lasa, G., Justel, D., Gonzalez, I., Iriarte, I., & Val, E. (2017). Next generation of tools for industry to evaluate the user emotional perception: the biometric-based multimethod tools. The Design Journal, 20(sup1), S2771–S2777. doi:10.1080/14606925.2017.1352788",
            "year": "2007",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The Emotron is software that allows the collection of emotional data during a process of test of tasks. It generates diagrams of task, which are authentic radiographies of the emotional evolution of the user that afterwards are crossed and related to the rest of tools",
            "general_procedure": "Data from the Emotron and Emotracking, associated to the data from user, time and task, is analyzed together with the images of the module of capture of the facial expression of the user during the interaction. In this way, we associate the emotional labels to the facial expression and the protocol of thinking aloud in that precise moment, as well as data of pupillometry and thermal areas in screen."
        },
        {
            "ux_instruments": "Emoscope - PULSETRON",
            "reference": "Lasa, G., Justel, D., Gonzalez, I., Iriarte, I., & Val, E. (2017). Next generation of tools for industry to evaluate the user emotional perception: the biometric-based multimethod tools. The Design Journal, 20(sup1), S2771–S2777. doi:10.1080/14606925.2017.1352788",
            "year": "2007",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The Pulsetron is the module that collects polygraphic data with the aim of having a better understanding of the psychological and emotional reality of the user.",
            "general_procedure": "Data from the Emotron and Emotracking, associated to the data from user, time and task, is analyzed together with the images of the module of capture of the facial expression of the user during the interaction. In this way, we associate the emotional labels to the facial expression and the protocol of thinking aloud in that precise moment, as well as data of pupillometry and thermal areas in screen."
        },
        {
            "ux_instruments": "Emotion Sampling Device (ESD)",
            "reference": "HOLE, Linda; WILLIAMS, Oliver M. The emotion sampling device (ESD). In: Proceedings of the 21st British HCI Group Annual Conference on People and Computers: HCI... but not as we know it-Volume 2. BCS Learning & Development Ltd., 2007. p. 177-178.",
            "year": "2007",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The emotion sampling device (ESD) has been developed in the light of ever-increasing interest in the area of affective computing, and out of a need to better understand the effect that electronic products have on the emotions of their users. ESD takes reference from the work of Lang, who concluded that emotion and its processes manifest themselves in the visceral, behavioural and verbal states, and Norman, who developed this further to suggest that the visceral and behavioural states exist in the subconscious space, while the verbal state exists in the conscious space, and only there do we achieve emotion. With this in mind,",
            "general_procedure": "The ESD consists of either a PDA or mobile phone which runs a mobile Java application and provides the user with a series of appraisal questions from which a basic emotional profile can be defined. The emotion sampling software system is capable of being ported to any device supporting the mobile Java architecture."
        },
        {
            "ux_instruments": "EmuJoy",
            "reference": "NAGEL, Frederik et al. EMuJoy: Software for continuous measurement of perceived emotions in music. Behavior Research Methods, v. 39, n. 2, p. 283-290, 2007.",
            "year": "2007",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Audiovisual",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "EMuJoy is a free software solution for the continuous measurement of responses to different media, using a joystick, mouse or any other human-computer interface and a software interface that is a two-dimensional chart area.",
            "general_procedure": "The main application is run on the computer of a subject, where the stimuli are presented. The researcher controls the application through a remote control software that allows you to select, start and stop, and so on, to be performed online. Communication between the server and the local application is based on the TCP protocol. The researcher can choose any media available on the network (local or the Internet). The separate parts of the program are usually started on different computers; however, it is also possible that all components run on only one computer."
        },
        {
            "ux_instruments": "End‐user Computing Satisfaction (EUCS)",
            "reference": "Abdinnour‐Helm, Sue F., Barbara S. Chaparro, and Steven M. Farmer. \"Using the end‐user computing satisfaction (EUCS) instrument to measure satisfaction with a web site.\" Decision Sciences 36.2 (2005): 341-364.",
            "year": "2005",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Online plataform",
            "ux-quality": "Satisfaction",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "Usability practitioners can use the EUCS to measure end-user satisfaction with a Web site and use the feedback for improving Web-site design",
            "general_procedure": "Participants are asked to complete a set of tasks and then complete the EUCS instrument"
        },
        {
            "ux_instruments": "Emotion Self-assessment Tool (ESAT)",
            "reference": "Granato, Marco, et al. \"Software and Hardware Setup for Emotion Recognition During Video Game Fruition.\" Proceedings of the 4th EAI International Conference on Smart Objects and Technologies for Social Good. ACM, 2018.",
            "year": "2018",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "Valence and Arousal",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "ESAT is an innovative method for acquiring users' emotional self-evaluation in medium-term experiments.",
            "general_procedure": "ESAT is used after the video game session for self-assessment of the participant's emotional states. ESAT works with the acquisition of data from physiological information software (DAPIS). A screen video during the game session is recorded by placing the DAPIS in the upper left area. DAPIS contains two colored bars used to synchronize the physiological data with the self-assessment information acquired by ESAT."
        },
        {
            "ux_instruments": "Experience Sampling Form (ESM)",
            "reference": "Csikszentmihalyi M, Larson R. 1992. Validity and reliability of the Experience Sampling Method. See deVries 1992, pp. 43–57",
            "year": "1992",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "Full ESM: 1. It can be used to obtain empirical data on the following types of variables: a) frequency and patterning of daily activity, social interaction, and changes in location; b) frequency, intensity, and patterning of psychological states, i.e., emotional, cognitive, and conative dimensions of experience; c) frequency and patterning of thoughts, including quality and intensity of thought disturbance. 2. ESM is a means for collecting information about both the context and content of the daily life of individuals. This purpose is shared by other method,s, but the unique advantage of ESM is its ability to capture daily life as it is directly perceived from one moment to the next, affording an opportunity to examine fluctuations in the stream of consciousness and the links between the external context and the contents of the mind. At the signal, the respondent writes down information about his or her momentary situation and psychological state on the ESF self-report questionnaire. Items contained in the form vary depending on the investigator's goal.",
            "general_procedure": "The method achieves this degree of immediacy by asking individuals to provide written responses to both open- and closed-ended questions at several random points throughout each day of a normal week, whenever a signaling device - a pager or a Palm Pilot - prompts them to respond. The questions can be fully tailored to the interests and goals of the researcher but generally include queries focused on physical context (location, time of day), social context (number and description of others sharing the moment), activities, thoughts, feelings, and cognitive and motivational self-appraisals. The ESF includes open questions about location, social context, primary and secondary activity, content of thought, time at which the ESF is filled out, and a number of Likert scales measuring several dimensions of the respodent's perceived situation including affect, activation, cognitive eficiency and motivation."
        },
        {
            "ux_instruments": "Experience Diary",
            "reference": "Gomez, Rafael Ernesto. The evolving emotional experience with portable interactive devices. Diss. Queensland University of Technology, 2012.",
            "year": "2012",
            "type_of_instrument": "Others (diary template)",
            "type_of_approach": "Quali-quantitative ",
            "application_domain": "Mobile devices",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Explore  the  emotional  experience  of  interacting  with  portable  devices  in everyday  use. ",
            "general_procedure": "The diaries were used by participants to record relevant interactions with the products as they experienced them over six months. They were asked to fill out the diary once a week. The structure of the diary provided for up to three  experiences  per  week.  Participants  were  asked  to  reflect  primarily  on  the  emotional  experiences with  the product during interactions by answering the following questions: (i) context of interaction (location/time/date); (ii) activity performed (purpose of use); (iii) who was present during interactions (alone/other people/crowd) and (iv) summary  of their perception of the emotional experience (perceived emotional reaction to experience). The participants  recorded  the  main  details  of  their  interactions  with  the  product  and  rated  the  overall  emotional experience using the Emotional Chart."
        },
        {
            "ux_instruments": "Eyeface",
            "reference": "Lasa, G., Justel, D., & Retegi, A. (2015). Eyeface: A new multimethod tool to evaluate the perception of conceptual user experiences. Computers in Human Behavior, 52, 359–363.",
            "year": "2015",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The Eyeface consists of two computer workstations, each running specific tools, the Eye-tracking and the Facereader",
            "general_procedure": "For this research work the Facereader’s webcam is installed on the top of the Eye-tracking device. Thus, two computers manage data, but the experiment is performed in front of one. Tte Facereader analyses the useremotional reactions in a delimited period of time. To do so, images of the user’s face are recorded and the data is translated into human specific emotions. The device classifies the facial expressions into 7 different fields: neutral, happy, sad, angry, surprised, scared and disgusted"
        },
        {
            "ux_instruments": "Facereader",
            "reference": "Uyl, M. den, Kuilenburg, H. van & Lebert, E. (2005). FaceReader: an online facial expression recognition system. Measuring Behavior 2005, 5th International Conference on Methods and Techniques in Behavioral Research, 30 August - 2 September 2005, Wageningen, The Netherlands.",
            "year": "2005",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "FaceReader is able to describe facial expressions and other facial features online with a remarkable accuracy. alternative to traditional keyboard and mouse commands. The human ability to read emotions from someone’s facial expressions is the basis of facial affect processing that can lead to expanding interfaces with emotional communication and, in turn, to obtaining a more flexible, adaptable, and natural interaction between humans and machines. There is a network to classify the emotional expression shown on a face in one of the categories: happy, angry, sad, surprised, scared, disgust or neutral. These emotional categories are also known as the “basic emotions” or “universal emotions”",
            "general_procedure": "The core problem of face analysis is how to simultaneously account for the three major source of variance in face images: pose/orientation, expression and lighting. To counter the problems caused by these sources of variation, the FaceReader classifies a face in three consecutive steps: 1. Face finding: an accurate position of a face is found using a method called the Active Template Method. The Active Template Method displaces a deformable face template over an image, returning the most likely face position or multiple positions if we allow more than one face to be analyzed; 2. Face modeling: Next, we use a model-based method called the Active Appearance Model (AAM) to synthesize an artificial face model, which describes both the locations of key points, as well as the texture of the face in a very low dimensionality. The AAM uses a set of annotated images to calculate the main sources of variation found in face images and uses PCA compression to reduce the model dimensionality. New face models can then be described as deviations from the mean face, using a compact vector called the “appearance vector”; 3: Face classification: The final stage in the FaceReader architecture is the actual classification of the expression or facial features we are interested in. This can be done in a very straightforward way by training an artificial neural network, which takes the AAM appearance vector as input. Given enough training data, we can train the network to learn to classify any facial feature as long as this feature is well modeled in the synthesized faces."
        },
        {
            "ux_instruments": "Facial Action Coding System (FACS)",
            "reference": "Ekman, Paul. \"Facial action coding system (FACS).\" A human face (2002). AND https://socialexploits.com/blog/facial-action-coding-system-explained/",
            "year": "2002",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The Facial Action Coding System (FACS) is a scientific system designed to measure human facial movements. 1 FACS is an anatomically-based comprehensive system. This means FACS can be used to describe any possible set of facial movements.",
            "general_procedure": "The act of describing facial movements using the Facial Action Coding System is called FACS coding (or scoring). Multiple FACS codes are strung together using plus (‘+’) signs. For example 1+2 represents raising the inner and outer portions of the eyebrow (i.e. raising the entire eyebrow.) FACS also includes a system to describe the intensity of each AU by affixing a letter A through E after the numeric code but before the plus sign. The intensity range for each letter is: Trace (A) Slight (B) Marked / Pronounced (C) Severe / Extreme / Maximum (D) Extreme / Maximum (E) To continue the previous example, 1E+2E represents extreme (or maximal) raising of the inner and outer portions of the eyebrows."
        },
        {
            "ux_instruments": "Frequent EDA and Event Logging  (FEEL)",
            "reference": "Ayzenberg, Y., Hernandez Rivera, J., & Picard, R. (2012). FEEL. Proceedings of the 2012 ACM Annual Conference Extended Abstracts on Human Factors in Computing Systems Extended Abstracts - CHI EA ’12.",
            "year": "2012",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Stress",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A system for the acquisition, processing and visualization of biophysiological signals and contextual information. ",
            "general_procedure": "The system comprises a mobile client application (FMC) and a backend server, The mobile client collects contextual information: phone call details, email reading details, calendar entries, and user location at a fixed interval that is transmitted to the backend server. The backend server stores the contextual information and biophysiological signal data that is uploaded by the user, processes the information and provides a novel interface for viewing the combined data."
        },
        {
            "ux_instruments": "Feeltrace",
            "reference": "ENGAGE Web site. Cowie, R., Douglas-Cowie, E., Savvidou, S., McMahon, E., Sawey, M., & SchroÌder, M. (2000). `FEELTRACE': An Instrument for Recording Perceived Emotion in Real Time, ISCA Workshop on Speech & Emotion, Northern Ireland 2000, p. 19-24",
            "year": "2000",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "FEELTRACE is an instrument developed to let observers track the emotional content of a stimulus as they perceive it over time, allowing the emotional dynamics of speech episodes to be examined. It is based on activation evaluation space, a representation derived from psychology.",
            "general_procedure": "The essential idea is to present activationevaluation space as a circle on a computer screen, and to have observers record their impression of emotional state by moving a cursor to the appropriate position in the space using a mouse. The development task is to ensure that users do that in a way that is consistent and whose meaning is reasonably clear"
        },
        {
            "ux_instruments": "Flow State Scale-2",
            "reference": "Jackson, Susan A., and Robert C. Eklund. \"Assessing flow in physical activity: The flow state scale–2 and dispositional flow scale–2.\" Journal of Sport and Exercise Psychology 24.2 (2002): 133-150.",
            "year": "2002",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Flow",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "Self-report instrument designed to evaluate flow experiences in physical activity.",
            "general_procedure": "Participants were recruited into college classes, sports teams and events such as triathlons. A standard introduction and instructions were given to all participants, and consent procedures were followed. Dispositional measures were completed at a time separated from the participation of participants in physical activity. The Flow State Scale was given to respondents to complete after participating in their core activity."
        },
        {
            "ux_instruments": "Fun Questionnaire",
            "reference": "Fun Questionnaire (A. Donker.Human factors in educational software for young children.PhD thesis, 2005)",
            "year": "2005",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Fun",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "Human/user focus",
            "main_ideia": "The child is asked to indicate how much fun a selected educational software program has been, answering 14 questions about their attitudes toward that program.",
            "general_procedure": "Experiment reported in the article: the researcher explained to the children that she would ask some questions to determine how they felt about two of the softwares they used regularly in the classroom. After emphasizing that there were no right or wrong answers, she asked the fourteen Fun Questionnaire questions first about one program and then another. The children answered the questions individually, to reduce the risk of socially appropriate responses by ticking a \"yes\" or \"no\" box after each question. When all the children in the class answered the questions, five children were randomly selected to work with Leescircus software. They were individually picked out of the classroom, worked with Leescircus for about fifteen minutes and then answered the Fun Questionnaire again individually. Finally, the experimenter completed the checklist for both programs."
        },
        {
            "ux_instruments": "Fun Toolkit - AGAIN AGAIN TABLE",
            "reference": "J. C. Read and S. MacFarlane. Using the fun toolkit and other survey methods to gather opinions in child computer interaction. In Proc. IDC '06, pages 81{88,2006.",
            "year": "2006",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Fun",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "Human/user focus",
            "main_ideia": "The Again - Again table was designed to capture an idea of engagement by asking the children whether or not they would do the activity again.",
            "general_procedure": "This table lists the activities on the left hand side, and has three columns headed Yes, Maybe, and No. The child ticks either yes, maybe or no for each activity, having in each case considered the question ‘Would you like to do this again?’"
        },
        {
            "ux_instruments": "Fun Toolkit - FUNSORTER",
            "reference": "J. C. Read and S. MacFarlane. Using the fun toolkit and other survey methods to gather opinions in child computer interaction. In Proc. IDC '06, pages 81{88,2006.",
            "year": "2006",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Fun",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "Human/user focus",
            "main_ideia": "The fun sorter allowed children to rank items against one or more constructs. This was intended to record the children’s opinions of the technology or activity, to gain a measure of the child’s engagement.",
            "general_procedure": "This Fun-Sorter has one or more constructs and a divided line (or table) that has as many spaces in it as there are activities to be compared. The children either write the activities in the spaces, or for younger children, picture cards can be made and placed on the empty grid."
        },
        {
            "ux_instruments": "Fun Toolkit - SMILEOYMETER",
            "reference": "J. C. Read and S. MacFarlane. Using the fun toolkit and other survey methods to gather opinions in child computer interaction. In Proc. IDC '06, pages 81{88,2006.",
            "year": "2006",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Fun",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "Human/user focus",
            "main_ideia": "Fun Toolkit consits of several tools, which measure the three fun dimensions expectations, engagement, and endurability.",
            "general_procedure": "It is based on a 1-5 Likert scale, and uses pictorial representations that the children contributed."
        },
        {
            "ux_instruments": "Game Engagement Questionnaire",
            "reference": "J.  H.  Brockmyer,  C.  M.  Fox,  K.  A.  Curtiss,  E.  McBroom,  K.  M.Burkhart, and J. N. Pidruzny. The development of the Game Engage-ment Questionnaire: A measure of engagement in video game-playing.Journal of Experimental Social Psychology, 45(4):624–634, jul 2009)",
            "year": "2009",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Engagement",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "It was developed to measure the subjective experience of deep engagement in violent video games.",
            "general_procedure": "Participants are given information about the study and signed informed consent, including consent for videotaping. Next, they are explained about the purpose of the study. Participants are instructed to complete the questionnaire with respect to their typical video game-playing experience."
        },
        {
            "ux_instruments": "Game experience questionnaire (GEQ) - inGame Questionnaire ",
            "reference": "Poels, K., De Kort, Y. A. W., & IJsselsteijn, W. A. (2007). D3. 3: Game Experience Questionnaire: development of a self-report measure to assess the psychological impact of digital games.",
            "year": "2008",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "(1) Sensory and Imaginative Immersion, (2) Tension, (3) Competence, (4) Flow, (5) Negative Affect, (6) Positive affect, (7) Challenge.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The in-game experience questionnaire (iGEQ) has the exact same component structure as the core questionnaire, but only consists of two of the five or six items for every component. ",
            "general_procedure": "It can be administered multiple times during a gaming session. Consists of only two items per component"
        },
        {
            "ux_instruments": "Game experience questionnaire (GEQ) - The core questionnaire",
            "reference": "Poels, K., De Kort, Y. A. W., & IJsselsteijn, W. A. (2007). D3. 3: Game Experience Questionnaire: development of a self-report measure to assess the psychological impact of digital games.",
            "year": "2008",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "(1) Sensory and Imaginative Immersion, (2) Tension, (3) Competence, (4) Flow, (5) Negative Affect, (6) Positive affect, (7) Challenge.",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "For the core GEQ, the factor solution and scale analyses provided a clear and clean structure of seven components (1) Sensory and Imaginative Immersion, (2) Tension, (3) Competence, (4) Flow, (5) Negative Affect, (6) Positive affect, and (7) Challenge. These subscales, each reliably measuring unique components of game experience, have 5 or 6 items",
            "general_procedure": "This questionnaire is administered immediately after a gaming session This is the heart of the GEQ, probing multiple components of game experience. Every component should consist of 4-6 items, with high internal consistency."
        },
        {
            "ux_instruments": "Game experience questionnaire (GEQ) - The post-game questionnaire ",
            "reference": "Poels, K., De Kort, Y. A. W., & IJsselsteijn, W. A. (2007). D3. 3: Game Experience Questionnaire: development of a self-report measure to assess the psychological impact of digital games.",
            "year": "2008",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "Emotion",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The post-game module is aimed towards measuring how people feel after they have stopped playing. Assess postivie experience, negative experience, tiredness, return to reality",
            "general_procedure": "Probe the gamers’ experience after having played the game and any after effects (e.g., returning to reality, fatigue, pride, guilt)."
        },
        {
            "ux_instruments": "Game experience questionnaire (GEQ) - The social presence module ",
            "reference": "Poels, K., De Kort, Y. A. W., & IJsselsteijn, W. A. (2007). D3. 3: Game Experience Questionnaire: development of a self-report measure to assess the psychological impact of digital games.",
            "year": "2008",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "Social Presence",
            "target_users_": "all types of users",
            "framework": "Social Nature of UX",
            "main_ideia": "The social presence module (SPGQ), probing gamers’ experience of and involvement with their co-player(s). This module only applies to situations where digital gamers played with or against one or more social entities, be they co-located players, online players, or virtual players",
            "general_procedure": "It is applicated after the players finish playing."
        },
        {
            "ux_instruments": "Geneva Appraisal Questionnaire",
            "reference": "Scherer, K. R. Appraisal considered as a process of multi-level sequential checking. In K. R. Scherer, A. Schorr, & T. Johnstone (Eds.), Appraisal processes in emotion: Theory, methods, research (pp. 92-120). Oxford University Press, New York, 2001",
            "year": "2001",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Appraisal",
            "sub_qualities_or_valence": "(1) intrinsic pleasantness,  (2) novelty, (3) goal/need conduciveness, (4) coping potential, and (5) norm/self compatibility.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Its purpose is to assess, as much as is possible through recall and verbal report, the results of an individual's appraisal process in the case of a specific emotional episode. To do so, the instrument contains questions that tap the appraisal criteria suggested by Scherer's model (the Stimulus Evaluation Checks, SECs). ",
            "general_procedure": "The participants must recall moments when they experienced intense emotion, either positive or negative.  It can be something that really happened or that they expected ti happen.  The events might have been brought about by they, by someone else, or by natural causes. Then they must try to remember some of the strongest emotional experiences that they have had in recent times and then select a number of episoded that they thought of spontaneously.  They must try to recall as many details as possible that are pertinent to the chosen emotion episode. Then, they must respond to the questions on the following pages by placing a check mark in the appropriate space for the respective scale. If a particular question does not make sense in a specific situation, they can mark the circle “does not apply”"
        },
        {
            "ux_instruments": "Geneva Emotion Wheel",
            "reference": "BÄNZIGER, Tanja; TRAN, Véronique; SCHERER, Klaus R. The Geneva Emotion Wheel: A tool for the verbal report of emotional reactions. Poster presented at ISRE, v. 149, p. 271-294, 2005.",
            "year": "2005",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Consists of discrete emotion terms corresponding to emotion families that are systematically aligned in a circle.",
            "general_procedure": "Underlying the alignment of the emotion terms are the two dimensions valence (negative to positive) and control (low to high), separating the emotions in four quadrants: Negative/low control, negative/high control, positive/low control, and positive/high control.  The response options are “spikes” in the wheel that correspond to different levels of intensity for each emotion family from low intensity (towards the center of wheel) to high intensity (toward the circumference of the wheel). Also, in the very center of the wheel, the response options “no emotion” and “other emotion” is offered.  The design of the GEW has elements of a free response format, a discrete emotion response format, and a dimensional approach to emotions. The free response format is reflected in the response option “other emotion” and gives respondents much freedom to express themselves. "
        },
        {
            "ux_instruments": "Hedonic Utility scale (HED/UT)",
            "reference": "K. E. Voss, E. R. Spangenberg, and B. Grohmann. Measuring the hedonic and utilitarian dimensions of consumer attitude. Journal of Marketing Research, 40(3):310 -- 320, 2003",
            "year": "2003",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Hedonic and Pragmatic",
            "sub_qualities_or_valence": "-",
            "target_users_": "Role-specific (consumers)",
            "framework": "User/artifact/environment relations",
            "main_ideia": "To measure the hedonic and utilitarian dimensions of consumer attitudes toward product categories and different brands within categories.",
            "general_procedure": "The hedonic/utilitarian (HED/UT) scale includes tem semantic differential response items, five of which refer to the hedonic dimension and five of which refer to the utilitarian dimension of consumer attitudes."
        },
        {
            "ux_instruments": "Human Computer trust",
            "reference": "Madsen, M., Gregor, S.: Measuring Human-Computer Trust. In: Gable, G., Viatle, M. (eds.) 11th Australasian Conference on Information Systems, p. 53 (2000) and http://selfdeterminationtheory.org/intrinsic-motivation-inventory/",
            "year": "2000",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Trust ",
            "sub_qualities_or_valence": "(1) Perceived understandability, (2) Perceived Technical Competence, (3) Perceived reliability, (4) Personal Attachment; (5) Faith.",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "A reliable and valid measure of HCT and may now be used to more fully investigate the structure of HCT in the context of computer-aided decision-making and the dynamics of HCT development.",
            "general_procedure": "There are affirmations related to five constructs: perceived reliability, perceived technical competence, perceived understandability, faith, personal attachment"
        },
        {
            "ux_instruments": "i-PANAS-SF",
            "reference": "Karim, J., Weisz, R., & Rehman, S. U. (2011). International positive and negative affect schedule short-form (I-PANAS-SF): Testing for factorial invariance across cultures. Procedia - Social and Behavioral Sciences, 15, 2016–2022.",
            "year": "2011",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "positive affectivity and positive affectivity",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The I-PANAS-SF is composed of two ten-item mood scales: one to measure positive affectivity and the other to measure negativity affectivity",
            "general_procedure": "Interviewees are asked to rate positive and negative adjectives according to the degree to which each describes how they felt during a specified period."
        },
        {
            "ux_instruments": "Igroup Presence Questionnaire",
            "reference": "T. Schubert, F. Friedmann, and H. Regenbrecht, “The Experience of Presence: Factor Analytic Insights,” Presence Teleoperators Virtual Environ., vol. 10, no. 3, pp. 266–281, Jun. 2001 & J. Vasconcelos-Raposo et al., “Adaptation and Validation of the Igroup Presence Questionnaire (IPQ) in a Portuguese Sample,” Presence Teleoperators Virtual Environ., vol. 25, no. 3, pp. 191–203, Dec. 2016",
            "year": "2016",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Presence",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "The questionnaire contains 14 items on a five-point Likert scale with the following three subscales: spatial presence (the feeling of being physically present in the virtual environment), experiential realism (measures the subjective experience of realism in the virtual environment), and involvement",
            "general_procedure": "After using the virtual environment, the questionnaire questions are answered by the participants."
        },
        {
            "ux_instruments": "Intrinsic motivation inventory (IMI)",
            "reference": "Ryan, R. M. (1982). Control and information in the intrapersonal sphere: An extension of cognitive evaluation theory. Journal of Personality and Social Psychology, 43, 450-461.",
            "year": "1982",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Other (laboratory experiments)",
            "ux-quality": "Intrinsic motivation",
            "sub_qualities_or_valence": "(1) Interest/enjoyment, (2) Perceived competence, (3) effort, (4) Value/usefulness, (5) Felt pressure and tension, (6) Perceived choice while performing a given activity,",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The IMI was developed to assess participants’ subjective experience related to experimental tasks. Specifically, it is used in intrinsic motivation laboratory experiments in which participants have worked on an interesting activity within some experimental condition, and the IMI assesses their levels of interest/enjoyment; perceived competence; effort; value/usefulness; felt pressure and tension; and perceived choice while they were performing the activity.",
            "general_procedure": "On the scale page, there are five sections. First, the full 45 items that make up the 7 subscales are shown, along with information on constructing your own IMI and scoring it. Then, there are four specific versions of the IMI that have been used in past studies. This should give you a sense of the different ways it has been used. These have different numbers of items and different numbers of subscales, and they concern different activities. First, there is a standard, 22-item version that has been used in several studies, with four subscales: interest/enjoyment, perceived competence, perceived choice, and pressure/tension. Second, there is a short 9-item version concerned with the activity of reading some text material; it has three subscales: interest/enjoyment, perceived competence, and pressure/tension. There is also the 25-item version that was used in the internalization study, including the three subscales of value/usefulness, interest/enjoyment, and perceived choice. Finally, there is a 29-item version of the interpersonal relatedness questionnaire that has five subscales: relatedness, interest/enjoyment, perceived choice, pressure/tension, and effort."
        },
        {
            "ux_instruments": "IoT Checklist",
            "reference": "ALMEIDA, Rodrigo L.A. et al. Towards Developing a Practical Tool to Assist UX Evaluation in the IoT Scenario. Anais Estendidos do Simpósio Brasileiro de Sistemas Multimídia e Web (WebMedia), [S.l.], p. 91-95, oct. 2018.",
            "year": "2018",
            "type_of_instrument": "Others (observational checklist)",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "User/artifact/environment relations",
            "main_ideia": "An evaluation tool in the form of a checklist to support the observation of user behavior during interaction with an IoT application.",
            "general_procedure": "The checklist must be applied by at least two evaluators, one responsible for conducting the tasks to be performed by the users and another evaluator dedicated to the observation and completion of the tool. Evaluators must first verify that the IoT application has the sensitivity to context and programmability and that all checklist items present in the checklist will be observed in the evaluation. If it is identified that any item does not apply to the scope of the assessment, the observer must previously mark the tool \"do not apply (N / A)\" in order to avoid distractions during observation. It is recommended that the observer study the tool and gain familiarity with the check items. Conducting the pilot assessment can help the evaluators' familiarity with checklist checkpoints. It is recommended to start filling the tool with the items in the human-thing category that are related to the user's direct contact with the \"things\" in order to fulfill the set of tasks established in the evaluation. The subcategory \"general aspects of UX\" can be evaluated for the whole set of tasks of the experiment. However, the subcategories of \"context sensitivity\" and \"programmability\" can be observed in tasks that allow their observation in both categories. Thus, it is recommended that the evaluators prepare the evaluation environment so that it can reproduce contextual situations that are key to the operation of the IoT application, whether performed in the laboratory or in the actual context of use. After completing the items in the first category, items of the thing-thing. It is suggested to indicate in the evaluation planning the marking of the tasks directly related to the verification of these items. The reproduction of contextual situations will be paramount for the observation of these items. It is important to reinforce that the items in this category relate to the operation of the IoT environment and are not directly related to the user's actions."
        },
        {
            "ux_instruments": "IPTV UX Questionnaire",
            "reference": "BERNHAUPT, R. PIRKER,  M. Methodological Challenges of UX Evaluation in the Living Room: Developing the IPTV-UX Questionnaire. 2011",
            "year": "2011",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "Aesthetic visual impression (beauty and classic aesthetics); Emotion; Stimulation; Identification; Relatedness; and Meaning and Value. ",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": " A questionnaire which focuses on the evaluation of domestic media applications.",
            "general_procedure": "Opinion, values and judgments, as well as the questions on the interaction technology were based on a 5 point Likert scale. The questionnaire is structured in five sections: (1) The core user experience factors;  (2) User experience aspects related to the interaction technology used; (3) Relation between perceived user experience and the interaction technology as well as the possible influences of content and service; (4) Attitude of the user, evaluating how important the concepts stimulation, status (identification) and relatedness are for the specific participant; (5) The relation between usability and user experiences"
        },
        {
            "ux_instruments": "iScale - Constructive iScale",
            "reference": "Karapanos, E., Martens, J.-B., Hassenzahl, M. (2010) On the Retrospective Assessment of Users' Experiences Over Time: Memory or Actuality?. CHI'10 extended abstracts on Human factors in computing systems. Atlanta, ACM Press",
            "year": "2010",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A survey tool that aims at assisting users in reconstructing their experiences with a product. imposes a chronological order in the reconstruction of one's experiences. It assumes that chronological reconstruction results in recalling more contextual details surrounding the experienced events and that the felt emotion is constructed on the basis of the recalled contextual details",
            "general_procedure": "In iScale participants are asked to “sketch” how their opinion has changed from the moment of purchase till the present.  Identified segments are indicated by vertical lines. Each segment is coded for the type of experience report and type of sketch. Each sketch is annotated by the respective time period and participants are asked to narrate one or more experiences that induced this change in their perception of the respective product quality."
        },
        {
            "ux_instruments": "iScale - Value Account",
            "reference": "Karapanos, E., Martens, J.-B., Hassenzahl, M. (2010) On the Retrospective Assessment of Users' Experiences Over Time: Memory or Actuality?. CHI'10 extended abstracts on Human factors in computing systems. Atlanta, ACM Press",
            "year": "2010",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "Emotion and contextual details",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The Value-Account iScale tool explicitly distinguishes the elicitation of the two kinds of information: value-charged (e.g. emotional) and contextual details. It assumes that value-charged information can be recalled without recalling concrete contextual details of an experienced event due to the existence of a specific memory structure, called ValueAccount, that stores the frequency and intensity of one's responses to stimuli",
            "general_procedure": "In iScale participants are asked to “sketch” how their opinion has changed from the moment of purchase till the present.  Identified segments are indicated by vertical lines. Each segment is coded for the type of experience report and type of sketch. Each sketch is annotated by the respective time period and participants are asked to narrate one or more experiences that induced this change in their perception of the respective product quality."
        },
        {
            "ux_instruments": "The Interactive Sensual Evaluation Instrument (ISEI)",
            "reference": "Sirera, Judith, and Yujie Yang. \"The Interactive Sensual Evaluation Instrument.\"",
            "year": "2018",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "(1) Anger, (2) Fear, (3) Happiness, and (4) Sadness.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The toolkit consist of a basic cube shape in which different modules that can be attached on its six sides. The basic cube are hollow and a vibration module is placed inside. The attachable shapes were chosen from Sensual Evaluation Instrument - spiky, bubbly and stone. ",
            "general_procedure": "The main shape with a vibration module ans 18 modules are provided to the participants. The participant get t to interact with the given modules in order to become familiar with its functions and behaviours. In accordance with the perceived emotion of the stimulus, the user added modules to the basic shape and tuned the amplification of the vibration module."
        },
        {
            "ux_instruments": "Kansei Engineering Software",
            "reference": "SCHÜTTE, Simon; ALMAGRO, Lluis Marco. Development and Application of Online Tools for Kansei Engineering Evaluations. In: KEER2018, Go Green with Emotion. 7th International Conference on Kansei Engineering & Emotion Research 2018, 19-22 March 2018, Kuching, Malaysia. Linköping University Electronic Press, 2018. p. 20-28.",
            "year": "2018",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Feelings",
            "sub_qualities_or_valence": "-",
            "target_users_": "Customers ",
            "framework": "Human/user focus ",
            "main_ideia": "KESo software is a universal tool for Kansei Engineering studies. It is built around the general Kansei Engineering model from 2004 and follows its structure.",
            "general_procedure": "The created survey is putted online, and answered by suitable users. This can be done by simply posting an online questionnaire to the participants including images, videos, or sound files of the product in question. If other properties are supposed to be evaluated, the questionnaire can be carried out in a lab environment on mobile devices. When the data collection is finished (or even while collection data) the data can be analysed in the synthesis step using a different statistical tool. "
        },
        {
            "ux_instruments": "Method of Assessment of eXperience (MAX)",
            "reference": "CAVALCANTE, EMANUELLE ; RIVERO, LUIS ; CONTE, TAYANA . MAX: A Method for Evaluating the Post-use User eXperience through Cards and a Board. In: The 27th International Conference on Software Engineering and Knowledge Engineering, 2015. v. 1. p. 495-500.",
            "year": "2015",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "(1) Emotion, (2) Ease of Use, (3) Usefulness and (4) Intention to Use.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "MAX introduces a set of cards and a board to guide the user through the UX evaluation process. That way, the evaluator can gather information on the user’s emotions, how easy and useful it was to use the system, and his/her intention to use the system again if given the chance. The MAX method can be applied at any stage of the software development process, after the use of mockups, prototypes, or the final versions of interactive systems.",
            "general_procedure": "The evaluation is performed through the use of cards and a board. The MAX cards allow evaluating the UX in terms of four categories: (a) Emotion, (b) Ease of Use, (c) Usefulness and (d) Intention to Use. Each MAX card presents an avatar to portray and express the possible reactions that a user can express regarding the evaluated system."
        },
        {
            "ux_instruments": "MemoLine",
            "reference": "Vissers, Jorick, Lode De Bot, and Bieke Zaman. \"MemoLine: evaluating long-term UX with children.\" Proceedings of the 12th International Conference on Interaction Design and Children. ACM, 2013.",
            "year": "2013",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": " Usability, Challenge, Quantity of play and General Impression",
            "target_users_": "Children",
            "framework": "Product/artifact focus ",
            "main_ideia": "A  child-friendly  adaptation  of  the  UX Curve  method  to  study  long-term  user  experience  concerning games  in a  retrospective  way.",
            "general_procedure": "There is a timeline which visualizes the timespan starting from the moment that the child received the product until the day of the evaluation session. There are  three colors:   green   (i.e.   periods   of   positive   experiences),   red   (i.e. periods  of  negative  experiences)  and  grey  (i.e.  periods  of  non-usage).  The  children  receive a   pencil  for  each  color,  by  which they could mark  periods  on  the  timeline,   with  the  color  that resembled their experience at that moment in time."
        },
        {
            "ux_instruments": "Mental Effort",
            "reference": "T Meijman, F Zijlstra, M Kompier, H Mulders, 1986, The measurement of perceived effort, Ergonomics: Proceedings of the Ergonomics Society's, Taylor & Francis  and ",
            "year": "1986",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Mental effort",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A unidimensional scale to measure mental effort",
            "general_procedure": "Ratings of invested effort are indicated by a cross on a continuous line. The line runs from 0 to 150 mm, and every 10 mm is indicated. Along the line, at several anchor points, statements related to invested effort are given, e.g., ‘almost no effort’ or ‘extreme effort’. The scale is scored by measurement of the distance from the origin to the mark in mm. On the RSME the amount of invested effort into the task has to be indicated, and not the more abstract aspects of mental workload (e.g., mental demand, as is in the TLX, see below). These properties make the RSME a good candidate for self-report workload measurement."
        },
        {
            "ux_instruments": "Mobile Phone Usability Questionnaire (MPUQ)",
            "reference": "Ryu, Young Sam. Development of usability questionnaires for electronic mobile products and decision making methods. Diss. Virginia Tech, 2005.",
            "year": "2005",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Mobile devices",
            "ux-quality": "Usability",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "It was  developed throughout this series of studies evaluates the usability of mobile phones for the purpose of making decisions among competing variations in the end-user market, alternatives of prototypes during the development process, and evolving versions during an iterative design process. In addition, the questionnaire can serve as a tool for identifying diagnostic information to improve specific usability dimensions and related interface elements.",
            "general_procedure": "The participant is required to complete a predetermined set of tasks for each product. Then, after that, the user completes all of the MPUQ items."
        },
        {
            "ux_instruments": "Multimodal deep log based ux platform",
            "reference": "Hussain, J., Khan, W. A., Hur, T., Bilal, H. S. M., Bang, J., Hassan, A. U., … Lee, S. (2018). A Multimodal Deep Log-Based User Experience (UX) Platform for UX Evaluation. Sensors, 18(5), 1622. doi:10.3390/s18051622",
            "year": "2018",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "User’s emotion, perception, and usage experience and metric extractions of a particular phenomenon or object that will help quantify the UX of a person with respect to the product.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The  proposed  platform  collects  the  user  data  through  different  methods  and  sensors,  such  as audio, video, and biometrics, as well as user interaction data and surveys, such as self-reported data use for the UX evaluation .",
            "general_procedure": "The platform is composed of four layers: the data layer (DL), UX measurement layer (UXML), analytics layer (AL), and visualization server (VS). In short, the DL acquires and stores the data acquired from the multiple data sources, including audio  devices,  video  equipment,  biometric  devices,  surveys,  and  user  interaction  logs.  The  data acquired by DL is mainly employed by UXML to deduce the user’s emotion, perception, and usage experience. UXML deals with UX metric extractions of a particular phenomenon or object that will help quantify the UX of a person with respect to the product. The extracted information is then used by  the  AL  upon  the  UX  expert  request  to  enable  different  types  of  analytics  to  infer  the  informed decision.  The  final  layer  is  the  visualization  server,  which  serves  as  a  toolkit  for  the  UX  expert  to evaluate the digital product. "
        },
        {
            "ux_instruments": "NO NAME INFORMED",
            "reference": "Moura, Dinara, Magy Seif el-Nasr, and Christopher D. Shaw. \"Visualizing and understanding players' behavior in video games: discovering patterns and supporting aggregation and comparison.\" Proceedings of the 2011 ACM SIGGRAPH symposium on video games. ACM, 2011.",
            "year": "2011",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quantitative ",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Behavior ",
            "sub_qualities_or_valence": "(1) Time players spent per area, (2) time players spent talking to Non-Players Characters, (3) when and where players interacted with the map, (4) items collected and (5) player paths and movement",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Analysts can visualize data from all players within different time ranges. They can also visualize specific clusters (players with similar play styles), or a single player playthough in case of outliers, in a specific time range",
            "general_procedure": "After selecting the map analysts want to work with, they can choose the events they want displayed by using the top menu. Event categories are color coded, making it visually easy to connect between the event category chosen and its representation in the visualization. Analysts can open new windows with new data; thus they can compare players’ behaviors across different maps"
        },
        {
            "ux_instruments": "NO NAME INFORMED",
            "reference": "Schaefer, Kristin. \"The perception and measurement of human-robot trust.\" (2013).",
            "year": "2013",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Hardware and Robotics",
            "ux-quality": "Human-robot trust",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "A trust perception 40 item scale specific to HRI that focused on the antecedents and measurable factors of trust specific to the human, robot, and environmental elements. The finalized 40 item scale was designed as a pre-post interaction measure used to assess changes in trust perception specific to HRI. The scale was also designed to be used as post-interaction measure to compare changes in trust across multiple conditions. It was further designed to be applicable across all robot domains",
            "general_procedure": "The 40 item human-robot trust scale provided an overall percentage score across all items. Items were preceded by the question “What percentage of the time will this robot …” followed by a list of the items. Each item was a single word or short phrase, and the order of items was randomized for each participant. "
        },
        {
            "ux_instruments": "NO NAME INFORMED",
            "reference": "Schaefer, Kristin. \"The perception and measurement of human-robot trust.\" (2013).",
            "year": "2013",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Hardware and Robotics",
            "ux-quality": "Human-robot trust",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "The 14 item subscale can be used to provide rapid trust measurement specific to measuring changes in trust over time, or during assessment with multiple trials or time restrictions. This subscale is specific to functional capabilities of the robot, and therefore may not account for changes in trust due to the featurebased antecedents of the robot.",
            "general_procedure": "Trust score is calculated by reverse coding the ‘have errors,’ ‘unresponsive, and ‘malfunction’ items; summing the 14 item scores and dividing by 14. The 14 item scale included the following items:  Function successfully,  Act consistently,  Reliable,  Predictable,  Dependable,  Follow directions,  Meet the needs of the mission,  Perform exactly as instructed,  Have errors (Reverse Coded),   Provide appropriate information,  Unresponsive (Reverse Coded),  Malfunction (Reverse Coded),  Communicate with people,  Provide feedback"
        },
        {
            "ux_instruments": "NO NAME INFORMED",
            "reference": "Van Damme, Kristin, et al. \"360° Video Journalism: Experimental Study on the Effect of Immersion on News Experience and Distant Suffering.\" Journalism Studies (2018): 1-24.",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Audiovisual ",
            "ux-quality": "Immersion",
            "sub_qualities_or_valence": "(1) presence, (2) immersive tendencies, (3) enjoyment, (4) subjective involvement, and (5) engagement with distant suffering",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "To assess whether 360° international disaster news leads to a higher sense of presence, higher enjoyment, higher subjective involvement towards the topic, and increased engagement with distant suffering towards the victim.",
            "general_procedure": "First, participants receive questions on socio-demographics, level of news interest, level of technology affinity, experience with VR devices, and viewpoints on differences between societal groups. Next, participants were invited to watch the news story (see Stimulus Material). During the interventions, participants were observed by a researcher, and verbal reactions were noted. After this intervention, participants continued the questionnaire, assessing presence, immersive tendencies, enjoyment, subjective involvement, and engagement with distant suffering. Finally, by means of a short debrief, participants were asked to verbally reflect on their experiences"
        },
        {
            "ux_instruments": "NO NAME INFORMED",
            "reference": "Samardžija, Ana Ćorić. \"Measuring the Success of the Interactive Mobile Information Systems at the Individual Level of Use (PhD).\" University of Zagreb, University of Zagreb (2016).",
            "year": "2016",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Mobile devices",
            "ux-quality": "Success",
            "sub_qualities_or_valence": "(1) Information Quality Success Dimension [(a) Completeness, (b) Understandability, (c) Relevance, (d) Accuracy, (e) Currency], (2) System Quality attributes [(a) Adaptability, (b) Availability, (c) Reliability, (d) Response time, (e) Accessibility, (f) Personalization, (g) Security], (3) Success [ (a) Efficiency, (b) Enjoyment, (c) Satisfaction], (4) User Experience [(a) Aesthetics, (b) Stimulation, (c) Use, (d) Usefulness, (e) Privacy, (f) Usability, (g) Intention to reuse]",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "A questionnaire to measure the success of today’s interactive mobile information systems that are used at the individual level (e.g. for entertainment, information seeking, communication, etc.). ",
            "general_procedure": "The  scale goes from 1 to 5, 1 being strongly disagree and 5 strongly agree. "
        },
        {
            "ux_instruments": "NO NAME INFORMED",
            "reference": "Zaharias, Panagiotis, and Angeliki Poylymenakou. \"Developing a usability evaluation method for e-learning applications: Beyond functional usability.\" Intl. Journal of Human–Computer Interaction 25.1 (2009): 75-98.",
            "year": "2009",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "E-Learning applications",
            "ux-quality": "Usability",
            "sub_qualities_or_valence": "Content, Learning & Support, Visual Design, Navigation, Accessibility, Interactivity, Self-assessment & learnability and motivation to learn.",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "It combines web and instructional design parameters and associates them with the most prominent affective learning dimension, which is intrinsic motivation to learn. ",
            "general_procedure": "Interviewees are asked to evaluate the e-learning courses they have used and interacted with. They themselves manage the questionnaire and, for each question, are asked to circulate the answer that best describes their level of agreement with the statements."
        },
        {
            "ux_instruments": "Pleasure, Arousal and Dominance Abbreviated Scale (PAD Abbreviated) http://www.kaaj.com/psych/scales/emotion.html",
            "reference": "Mehrabian, A. (1995). Framework for a comprehensive description and measurement of emotional states. Genetic, Social, and General Psychology Monographs, 121, 339-361.",
            "year": "1995",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "(1) Pleasure, (2) Arousal, (3) Dominance ",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The PAD Emotion Scales, when used in the software package, supply a highly useful and convenient assessment of consumer emotional reactions to services, products, or combinations of products and services.",
            "general_procedure": "Experimenters are sometimes compelled to use abbreviated scales because respondents are required to rate a large number of stimuli. Accordingly, a 12-item abbreviated version of the PAD Emotion Scales also has been prepared. When respondents rate multiple stimuli, rating of the very first stimulus takes three to five minutes because some time is required to read the test instructions. Each of subsequent stimuli can be rated in two to three minutes. An additional and very important feature of the abbreviated scales is that the adjective pairs used are easy to understand. This makes the scales suitable for large-scale commercial and survey applications where respondents have a limited vocabulary (e.g., testing the emotional impact of a feature length film, television advertisement, shop or shopping mall, musical recording, political advertisement, personal image projected by a political candidate). These scales include:  A 4-item State Pleasure-Displeasure Scale A 4-item State Arousal-Nonarousal Scale A 4-item State Dominance-Submissiveness Scale Items of these three scales are intermixed within a 12-item inventory to minimize subject awareness of the scale dimensions, thereby enhancing validity. For each item, subjects place a check-mark in one of nine spaces separating two adjectives to indicate how they feel in a specific situation."
        },
        {
            "ux_instruments": "Pleasure, Arousal and Dominance Full-Length Scale",
            "reference": "Mehrabian, A. (1995). Framework for a comprehensive description and measurement of emotional states. Genetic, Social, and General Psychology Monographs, 121, 339-361.",
            "year": "1996",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "(1) Pleasure, (2) Arousal, (3) Dominance ",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "The PAD Emotion Scales, when used in the software package, supply a highly useful and convenient assessment of consumer emotional reactions to services, products, or combinations of products and services.",
            "general_procedure": "Should be used when precise assessments of emotions are needed. These scales include:  A 16-item State Pleasure-Displeasure Scale; A 9-item State Arousal-Nonarousal Scale; A 9-item State Dominance Submissiveness Scale. Items of these three scales are intermixed within a 34-item inventory to minimize subject awareness of the scale dimensions, thereby enhancing validity. For each item, respondent place a check-mark in one of nine spaces separating two adjectives to indicate how they feel in a specific situation. "
        },
        {
            "ux_instruments": "PANAS-X  ",
            "reference": "Watson, David, and Lee Anna Clark. \"The PANAS-X: Manual for the positive and negative affect schedule-expanded form.\" (1999).",
            "year": "1999",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Affect ",
            "sub_qualities_or_valence": "(1) Fear, (2) Sadness, (3) Guilt, (4) Hostility, (5) Shyness, (6) Fatigue, (7) Surprise, (8) Joviality, (9) Self-Assurance, (10) Attentiveness, and (11) Serenity.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A 60-item, expanded version of the PANAS. Consists of a number of words and phrases that describe different feelings and emotions. In addition to the two original higher order scales, the PANAS-X measures 11 specific affects: Fear, Sadness, Guilt, Hostility, Shyness, Fatigue, Surprise, Joviality, Self-Assurance, Attentiveness, and Serenity. The PANAS-X thus provides for mood measurement at two different levels.",
            "general_procedure": "The participants must read each item and then mark the appropriate answer in the space next to that word and indicate to what extent they felt this way during the past few weeks."
        },
        {
            "ux_instruments": "Pedagogically Meaningful Learning Questionnaire (PMLQ)",
            "reference": "Nokelainen, Petri. \"An empirical assessment of pedagogical usability criteria for digital learning material with elementary school students.\" Journal of Educational Technology & Society 9.2 (2006).",
            "year": "2006",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "E-Learning applications",
            "ux-quality": "Usability",
            "sub_qualities_or_valence": "Learner control, learner activity, cooperative/collaborative learning, goal orientation, applicability, added value, motivation, valuation of previews knowledge, flexibility and feedback.",
            "target_users_": "role-specific",
            "framework": "Product/artifact focus",
            "main_ideia": "A PMLQ (Pedagogically Meaningful Learning Questionnaire) research instrument was developed on the basis of the aforementioned technical and pedagogical usability criteria. The first version of the instrument contained 92 multiple-choice  items.",
            "general_procedure": "The  five-point  scale  ranged  from  1  (totally  disagree)  to  5  (totally  agree).  The  sixth  response option was “Not applicable”. The PMLQ has three parts. The first part concerns technical and pedagogical usability of the learning platform (or system) containing 43 items; the second is about technical usability of the learning material (24 items), and the  third  part  measures  pedagogical  usability  of  the  learning  material  (25  items).  The  propositions  are  clearly  marked when measuring issues about system or contents."
        },
        {
            "ux_instruments": "Prior Experience of Technology and Task Use - Children’s technology (generic) history questionnaire  (PETT -  CTHQ)",
            "reference": "Horton, Matthew Paul Leslie. Improving Validity and Reliability in Children’s Self Reports of Technology Use. Diss. University of Central Lancashire, 2013.",
            "year": "2013",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "Human/user focus ",
            "main_ideia": "The purpose of the CTHQ is to provide evidence of the general exposure a child has had to technology. This is not limited to a specific device or piece of technology but instead looks at their broad knowledge of technology as a whole. ",
            "general_procedure": "The CTHQ questionnaire was created to gather children's self-reports about their previous general experience of interacting with technology. This questionnaire is not specific to technology or task and therefore requires less adaptation than the previous two questionnaires. CTHQ can be used as an autonomous questionnaire when a basic level of exposure to the technology is required without the need for more detailed data from a specific technology or device."
        },
        {
            "ux_instruments": "Prior Experience of Technology and Task Use - Children’s task experience questionnaire (PETT - CTEQ)",
            "reference": "Horton, Matthew Paul Leslie. Improving Validity and Reliability in Children’s Self Reports of Technology Use. Diss. University of Central Lancashire, 2013.",
            "year": "2013",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "User/artifact/environment relations",
            "main_ideia": "The purpose of the CTEQ is to provide evidence of a child’s experience carrying out a specific task without putting that task into the context of a specific piece of technology",
            "general_procedure": "The CTEQ questionnaire was developed to collect the experience report on previous experience in the accomplishment of a work proposal not related to the technology in which a task was performed. The questionnaire was written to allow its use in any task related to the technology. If a data set is a task, the CTEQ questionnaire can be adapted and administered for each task. The CTEQ can be used as a stand-alone period for knowledge of a basic demand."
        },
        {
            "ux_instruments": "Prior Experience of Technology and Task Use - Children’s Technology Use Questionnaire (PETT - CTUQ)",
            "reference": "Horton, Matthew Paul Leslie. Improving Validity and Reliability in Children’s Self Reports of Technology Use. Diss. University of Central Lancashire, 2013.",
            "year": "2013",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "Children",
            "framework": "Human/user focus ",
            "main_ideia": "The purpose of the CTUQ is to provide evidence of a child’s experience with a specific piece of technology. It is in essence a prior experience questionnaire focussing on a single piece of technology",
            "general_procedure": "The CTUQ questionnaire was developed to gather the self-report of children from their previous experience with a specific piece of technology. The questionnaire was written to allow its use with any piece of technology. If a study involves more than one piece of technology, the CTUQ questionnaire could be adapted and administered for each piece of technology. The CTUQ can be used as an autonomous questionnaire to gather knowledge of a specific piece of technology if the use of other questionnaires within PETT is not considered necessary."
        },
        {
            "ux_instruments": "Playtracer",
            "reference": "Andersen, Erik, et al. \"Gameplay analysis through state projection.\" Proceedings of the fifth international conference on the foundations of digital games. ACM, 2010.",
            "year": "2010",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "One useful way to analyze games is to find areas where a large proportion of players fail. Playtracer helps to show the common ways that players succeed and fail, identify pitfalls and anomalies, and track how a particular player progresses through multiple levels. It is provided a simple interface to allow the user to adapt the visualization to explore the game space in detail",
            "general_procedure": "Playtracer takes in a list of all of the states that the player visited and a distance metric that calculates the distance between states, and creates a graph where the states are vertices and player movements are directed edges."
        },
        {
            "ux_instruments": "PocketBee",
            "reference": "Gerken, Jens. Longitudinal Research in Human-Computer Interaction. Diss. 2011.",
            "year": "2011",
            "type_of_instrument": "Others (diary template)",
            "type_of_approach": "Qualitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "-",
            "main_ideia": "A multimodal diary for longitudinal field research. The tool is based on Android smartphones and allows researchers to conduct remote longitudinal studies in a variety of ways. PocketBee is being developed for the Android OS and uses a client-server architecture.",
            "general_procedure": "By tapping on a core question, a diary entry is created that can then be enriched with data. The interface allows users to compose a diary entry out of several notes. The researcher, on the other hand, has immediate access to the diary entry via the control center (see Figure 30) or as soon as the device has a network connection (WiFi or GSM/3G).  In order to react to the data, the researcher can modify existing or create new core questions as well as create additional tasks and questionnaires individually for each participant. The last two reside on the lower part of the home-screen widget. Tasks are meant to provide specific instructions, such as “please take a picture of the power cable,” allowing the researcher to interact more closely with the participant, tightening the bond between the two as the latter receives direct feedback on his or her actions. This will also help to increase the motivation for continuous use of the diary. Questionnaires can be designed in an XML template that provides several different question types for most necessities, such as multiple selections, rating scales, or open-ended questions"
        },
        {
            "ux_instruments": "Positive and Negative Affect Scale (PANAS)",
            "reference": "WATSON, David; CLARK, Lee Anna; TELLEGEN, Auke. Development and validation of brief measures of positive and negative affect: the PANAS scales. Journal of personality and social psychology, v. 54, n. 6, p. 1063, 1988.",
            "year": "1988",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "(1) Interest, (2) stress, (3) excitement, (4) annoyance, (5) strength, (6) guilt, (7) scary, (8) hostility, (11) irritation, (12) alertness, (13) shame, (14) inspiration, (15) nervousness, (16) determination, (17) attention, (18) jitter, (19) action, (20) fear ",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Two 10-item mood scales that comprise the Positive and Negative Affect Schedule (PANAS).",
            "general_procedure": "This scale consists of a number of words that describe different feelings and emotions"
        },
        {
            "ux_instruments": "Product Emotion Measurement Instrument (PrEmo)",
            "reference": "DESMET, Pieter. Measuring emotion: Development and application of an instrument to measure emotional responses to products. In: Funology. Springer, Dordrecht, 2003. p. 111-123.",
            "year": "2003",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "(1) desire, (2) pleasant surprise, (3) inspiration, (4) amusement, (5) admiration, (6) satisfaction, (7) fascination. (8) indignation, (9) contempt, (10) disgust, (11) unpleasant surprise, (12) dissatisfaction, (13) disappointment, and (14) boredom",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "PrEmo is a non-verbal self-report instrument that measures 14 emotions that are often elicited by product design. Of these 14 emotions, seven are pleasant (i.e. desire, pleasant surprise, inspiration, amusement, admiration, satisfaction, fascination), and seven are unpleasant (i.e. indignation, contempt, disgust, unpleasant surprise, dissatisfaction, disappointment, and boredom). Instead of relying on the use of words, respondents can report their emotions with the use of expressive cartoon animations. In the instrument, each of the 14 measured emotions is portrayed by an animation by means of dynamic facial, bodily, and vocal expressions",
            "general_procedure": "The procedure of a PrEmo experiment is self-running. The computer screen displays instructions that guide respondents through the procedure, which includes an explanation of the experiment and an exercise. The program’s heart is the measurement interface, which was designed to be simple and intuitive in use. The top section of this interface depicts stills of the 14 animations. Each still is accompanied by a (hidden) three-point scale. These scales represent the following ratings: “I do feel the emotion,” “to some extent I feel the emotion,” and “I do not feel the emotion expressed by this animation.” The rating scales are ‘hidden behind’ the animation frames. A scale appears on the side of the animation frame only after the animation is activated by clicking on the particular still. The lower section of the interface displays a picture of the stimulus and an operation button. During an experiment, the respondents are first shown a (picture of a) product and subsequently instructed to use the animations to report their emotion(s) evoked by the product. While they view an animation, they must ask themselves the following question: “does this animation express what I feel?” Subsequently, they use the three-point scale to answer this question. Visual feedback of the scorings is provided by the background colour of the animation frame."
        },
        {
            "ux_instruments": "Presence Questionnaire - Immersive Tendency Questionnaire",
            "reference": "WITMER, Bob G.; SINGER, Michael J. Measuring presence in virtual environments: A presence questionnaire. Presence, v. 7, n. 3, p. 225-240, 1998.",
            "year": "1998",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Immersion",
            "sub_qualities_or_valence": "(1) Immersive tendencies, (2) current fitness or alertness, (3) ability to focus or redirect one's attention.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A few items (e.g., items 9, 10, and 15) measure immersive tendencies directly; others assess one’s current fitness or alertness, or measure the ability to focus or redirect one’s attention.",
            "general_procedure": "The PQ and ITQ use a seven-point scale format that is based on the semantic differential principle Like the semantic differential, each item is anchored at the ends by opposing descriptors. Unlike the semantic differential, the scale includes a midpoint anchor. The anchors are based on the content of the question stem, and in that respect, are more like the anchors used in common rating scales. The PQ and ITQ instructions asked respondents to place an ‘‘X’’ in the appropriate box of the scale in accordance with the question content and descriptive labels"
        },
        {
            "ux_instruments": "Presence Questionnaire - Presence Questionnaire ",
            "reference": "WITMER, Bob G.; SINGER, Michael J. Measuring presence in virtual environments: A presence questionnaire. Presence, v. 7, n. 3, p. 225-240, 1998.",
            "year": "1998",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Presence",
            "sub_qualities_or_valence": "(1) Control factors, (2) Sensory Factors, (3) Distraction Factors, (4) Realism Factors. ",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Questionnaires developed to measure presence in VEs. In addition it was developed an immersive tendencies questionnaire (ITQ) to measure differences in the tendencies of individuals to experience presence. These questionnaires are being used to evaluate relationships among reported presence and other research variables. The ITQ was developed to measure the capability or tendency of individuals to be involved or immersed.               The PQ measures the degree to which individuals experience presence in a VE and the influence of possible contributing factors (control, sensory, distraction and realism) on the intensity of this experience",
            "general_procedure": "The PQ and ITQ use a seven-point scale format that is based on the semantic differential principle Like the semantic differential, each item is anchored at the ends by opposing descriptors. Unlike the semantic differential, the scale includes a midpoint anchor. The anchors are based on the content of the question stem, and in that respect, are more like the anchors used in common rating scales. The PQ and ITQ instructions asked respondents to place an ‘‘X’’ in the appropriate box of the scale in accordance with the question content and descriptive labels"
        },
        {
            "ux_instruments": "Post-Study System Usability Questionnaire (PSSUQ)",
            "reference": "Lewis, James R. \"Psychometric evaluation of the PSSUQ using data from five years of usability studies.\" International Journal of Human-Computer Interaction 14.3-4 (2002): 463-488.",
            "year": "2002",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Satisfaction",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "The PSSUQ is a 19-item instrument designed for the purpose of assessing users’ perceived satisfaction with their computer systems.",
            "general_procedure": "Participants must respond a  7-point scale after using a system"
        },
        {
            "ux_instruments": "Questionnaire for User Interaction Satisfaction (QUIS)",
            "reference": "J. P. Chin, V. A. Diehl, and L. K. Norman. Development of an instru-ment measuring user satisfaction of the human-computer interface. InProceedings of the SIGCHI conference on Human factors in computingsystems - CHI ’88, pages 213–218, New York, USA, 1988. ACM Press.",
            "year": "1988",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Satisfaction",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "The Questionnaire for User Interaction Satisfaction(QUIS) is a usability testing tool designed to gauge computer user's subjective satisfaction with the computer interface. The QUIS contains a demographic questionnaire, an overall measure of satisfaction, and measures of user satisfaction in four specific interface aspects (screen factors, terminology and system feedback, learning factors, and system capabilities).",
            "general_procedure": "The QUIS contains a demographic questionnaire, a measure of overall system satisfaction along six scales, and hierarchically organized measures of four specific interface factors (screen factors, terminology and system feedback, learning factors, and system capabilities). Each area measures the overall satisfaction with that facet of the interface, as well as the factors that make up that facet, on a 9-point scale."
        },
        {
            "ux_instruments": "ReTUXE",
            "reference": "Maia, C. L. B., & Furtado, E. S. (2017). ReTUXE. Proceedings of the XVI Brazilian Symposium on Human Factors in Computing Systems - IHC 2017.",
            "year": "2017",
            "type_of_instrument": "Psychophysiology",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Emotion",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A framework to evaluate the hedonic user experience in real time, considering the user's emotion, using psychophysiological measures.",
            "general_procedure": "Prior to the experiment, user psychophysiological measures should be recognized. During the experiment, the user's emotions are estimated, based on their collected psychophysiological measures, which consists of: reading the physiological signals, recognizing changes in patterns, estimating the user's emotions and recording the main changes."
        },
        {
            "ux_instruments": "Self Assessment Manikin (SAM)",
            "reference": "BRADLEY, Margaret M.; LANG, Peter J. Measuring emotion: the self-assessment manikin and the semantic differential. Journal of behavior therapy and experimental psychiatry, v. 25, n. 1, p. 49-59, 1994.",
            "year": "1994",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "(1) Pleasure; (2) Arousal; (3) Dominance ",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A picture-oriented instrument called the Self-Assessment Manikin to directly assess the pleasure, arousal and dominance associated in response to an object or event. SAM ranges from a smiling happy figure to a frowning, unhappy figure when representing the pleasure dimension, and ranges from an excited, wide-eyed figure to a relaxed, sleepy figure for the arousal diension. The dominance dimension represents changes in control with changes in the size of SAM: a large figure indicates maximum control in the situation.",
            "general_procedure": "The user can place an 'x' over any of the five figures in each scale, or between any two figures, which results in a 9-pont rating scale for each dimension. A current computer version of the SAM figure dynamically changes along a 20-point scale for each of the three dimensions."
        },
        {
            "ux_instruments": "Sensual Evaluation Instrument (SEI)",
            "reference": "sbister, K., Hook, K., Sharp, M., and Laaksolahti, J. 2006. The sensual evaluation instrument: developing an affective evaluation tool. In Proc CHI '06. ACM, New York, NY, 1163-1172",
            "year": "2006",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "Different shaped objects are used by users during a usability test to express how they feel. After the test, an interview is conducted to interpret the results.",
            "general_procedure": "The participant interacts with a system and he has an easy access to physical objects with different shapes (spiky, smooth). When emotions arise during interaction, he can pick one of the shapes to express the emotion."
        },
        {
            "ux_instruments": "Service User Experience Questionnaire (ServUX Questionnaire)",
            "reference": "VÄÄNÄNEN-VAINIO-MATTILA, Kaisa; SEGERSTÅHL, Katarina. A Tool for Evaluating Service User eXperience (ServUX): Development of a Modular Questionnaire. In: User Experience Evaluation Methods, UXEM'09 Workshop at Interact. 2009.",
            "year": "2009",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Online plataform",
            "ux-quality": "Service Experience ",
            "sub_qualities_or_valence": "(1) Cross-platform and crossmedial interactions, (2) User-driven service composition, (3) Social communication and construction, (4) Dynamic content and functionality, (5) Contextual computing, (6) General-level issues.",
            "target_users_": "role-specific",
            "framework": "Product/artifact focus ",
            "main_ideia": "The purpose of the ServUX questionnaire is to help collect and organize data for assessing the capabilities of modern web services in promoting and supporting positive and engaging user experiences. The questionnaire can be used for evaluation, research as well as development purposes of web services. It identifies several factors or focus areas that constitute the essence of dynamic, social and crossmedial information services. It will also provide a platform for including new, emergent aspects of web services as they evolve from Web 2.0 to Web 3.0 and so forth. This flexibility is achieved through a modular approach to structuring the questionnaire",
            "general_procedure": "The users filled in an online version of the questionnaire containing modules that applied to the particular case. Statements in each module were also carefully adapted for each case in a way that would not compromise their content. In the Finnish field study, the users filled out the ServUX questionnaire twice: approximately one week after the study had started and at the end of the study. In the US-based trial, the users filled out the questionnaire at the end of the study. "
        },
        {
            "ux_instruments": "Simulator Sickness Questionnaire (SSQ)",
            "reference": "R. S. Kennedy, N. E. Lane, K. S. Berbaum, and M. G. Lilienthal, “Simulator Sickness Questionnaire: An Enhanced Method for Quantifying Simulator Sickness,” Int. J. Aviat. Psychol., vol. 3, no. 3, pp. 203–220, Jul. 1993 E de Carvalho¹, Marcele Regine, Rafael Thomaz da Costa¹, and Antonio Egidio Nardi¹. \"Simulator Sickness Questionnaire: tradução e adaptação transcultural.\" J Bras Psiquiatr 60.4 (2011): 247-52..",
            "year": "2011",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Cybersickness",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "User/artifact/environment relations",
            "main_ideia": "An instrument adapted from the Simulator Sickness Questionnaire to measure cybersickness.",
            "general_procedure": "The symptoms can be classified as: absent, mild, moderate or severe and scored from 0 to 3, respectively. To obtain the scores for each subscale (Oculomotor, Disorientation and Nausea), the symptoms are given specific weights, which must be multiplied by the score value assigned to each of them by the respondent. Then, just add the values ​​obtained to arrive at the total value of each subscale, which should be placed in formulas of conversion for the final score of each subscale. The total severity score is obtained by the sum of the values ​​obtained in each subscale (values ​​before the final score obtained by the conversion formulas) and the application in a specific formula that will indicate the final result of the scale"
        },
        {
            "ux_instruments": "Social Presence in Gaming Questionnaire (SPGQ)",
            "reference": "De Kort, Y.A.W., IJsselsteijn, W.A. and Poels, K., Digital games as social presence technology: Development of the Social Presence in Gaming Questionnaire (SPGQ). In Proceedings of PRESENCE 2007: The 10th International Workshop on Presence, (Barcelona, Spain, 2007), 195-203.",
            "year": "2007",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Social Presence",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Social Nature of UX",
            "main_ideia": "The Social Presence in Gaming Questionnaire can be regarded as a promising measure, having rendered reliable and easily interpretable scales, with satisfactory sensitivity and validity as evidenced by additional analyses performed on background variables. The SPGQ thus provides a useful tool for investigating the social use and social richness of digital games and gaming technologies (consoles, interaction devices).",
            "general_procedure": "Try out reported in the article: Participants were invited online to participate in a study on game experience. Before opening the link to the questionnaire, they had to approve a digital game (which was freely chosen by themselves). After playing the game, participants could click on a link that guided them to search online."
        },
        {
            "ux_instruments": "Standardized User Experience Percentile Rank Questionnaire (SUPR-Q)",
            "reference": "Sauro, Jeff. \"SUPR-Q: A comprehensive measure of the quality of the website user experience.\" Journal of usability studies 10.2 (2015): 68-86.",
            "year": "2015",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Online plataform",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "Usability, Trust, Appearance and loyalty",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A questionnaire that measures several critical aspects of the website user experience",
            "general_procedure": "Standardized questionnaires, such as SUPR-Q, can be administered during a usability test or out of a usability test. However, they are not a substitute for usability testing because they can not identify problems in an interface. SUPR-Q can be administered before and after website changes to measure how much improvement, if any, has been achieved. The normative scores of the SUPR-Q allow website owners to assess the website's usability, trust, appearance and loyalty."
        },
        {
            "ux_instruments": "Software Usability Measurement Inventory (SUMI)",
            "reference": "Kirakowski, J. & Corbett, M. (1993). SUMI - The Software Usability Measurement Inventory. British Journal of Educational Technology, 24 (3), 210-212",
            "year": "1993",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "(1) affect, (2) efficiency, (3) learnability, (4) helpuness, and (5) control.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "SUMI measures users perception of the usability of software. It provides a valid and reliable method for the comparasion of competing prodcs and difffering versions of the same product, as well as providing diagnostic information for future devolpments. It consists of a 50-item questionnaire devised in accordance with psychometric practice. It is intended to be administered to a sample of users who have had some experience of using the software to be evaluated.",
            "general_procedure": "There is first a global usability reading, which gives a single figure-of-merit approach. While this is useful as a summary, it is not itself terribly informative. The second layer has five sub-scales: affect, efficiency, learnability, helpuness, and control. The subscales relate to the users's perceptions of the qualities of the software they are interacting with, and each of the subscales has a specific meaning, given in the SUMI manual. The third layer is what is known as Item Consensual Analysis.  If therefore highlights very quickly whic aspects of your software stand out as in need of special attention and which are strong features."
        },
        {
            "ux_instruments": "Technology Acceptance Model Extended Version (TAM)",
            "reference": "R. Saad ́e and B. Bahli. The impact of cognitive absorption on perceivedusefulness and perceived ease of use in on-line learning: an extensionof the technology acceptance model.Information & Management,42(2):317–327, 2005.",
            "year": "2005",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "E-Learning applications",
            "ux-quality": "Cognitive absorption",
            "sub_qualities_or_valence": "Perceived usefulness, perceived ease of use and behavioral intention to use",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "An extended version of the Techonoly Acceptance Model (TAM), including cognitive absorption, to explain the acceptance of internet-based learning systems, which are being used in many universities and firms and whose adoption requies a solid understading of the user acceptace processes.",
            "general_procedure": "The items are measured using a five-point Likert-type scale with anchros from \"Strongly disagree\" to \"Strongly agree\". It includes items worded with proper negation and a shuffle of the items to reduce monotony of questions measuring the same construct."
        },
        {
            "ux_instruments": "TangiSAM",
            "reference": "Moreira, E. A., dos Reis, J. C., & Baranauskas, M. C. C. (2017). TangiSAM. Proceedings of the XVI Brazilian Symposium on Human Factors in Computing Systems - IHC 2017.",
            "year": "2017",
            "type_of_instrument": "Post-test Picture/object",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "Pleasure, arousal and dominance",
            "target_users_": "Children",
            "framework": "Human/user focus",
            "main_ideia": "TangiSAM consists of several sets of dolls for the three-dimensional representation of the three dimensions evaluated in the affective state. Its design includes representation in Braille in the different components of the solution and auditory feedback",
            "general_procedure": "To use TangiSAM, a moderator must initially register an activity in the system. After this registration, people can choose the dolls that reflect their affective states during a self-assessment activity. To register the affective states, the chosen dolls must be approximated one by one from the RFID reader so that the code related to their RFID tag is read and sent to the computer via the reader. The software will proceed with processing the choice. The choices of the affective states obey the following order: firstly, the doll for the Satisfaction is chosen; then the doll for Motivation and then the Doll on Control. At any time, the person can restart his choice by bringing the \"Restart\" management doll closer to the reader. At the end of the choice of each dimension, the person can \"Confirm\" or \"Do Not Confirm\" the choices, bringing the corresponding bicorder puppet closer to the reader. Then the system is automatically prepared for a new choice of affective states by another participant."
        },
        {
            "ux_instruments": "The Affective Slider ",
            "reference": "A. Betella and P.F.M.J. Verschure. 2016. The affective slider: A digital self-assessment scale for the measurement of human emotions. PLoS ONE 11, 2 (2016). https://doi.org/10.1371/journal.pone.0148037",
            "year": "2016",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Affect",
            "sub_qualities_or_valence": "Pleasure and Arousal",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A digital self-report tool consisting of two sliders for quick evaluation of pleasure and excitement.",
            "general_procedure": "After or while using a product, the user can use the Affecftive Slider to self-report their pleasure and excitement."
        },
        {
            "ux_instruments": "The Checklist of Trust between People and Auto-mation (CTPA)",
            "reference": "Jian, J.-Y., Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated Systems. International Journal of Cognitive Ergonomics, 4(1), 53–71. doi:10.1207/s15327566ijce0401_04",
            "year": "2000",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Human-Computer Trust",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "User/artifact/environment relations",
            "main_ideia": "A proposed confidence scale for man-machine confidence, which included 12 items to measure trust between people and automated systems.",
            "general_procedure": "After using an automation system, the scale is presented to the user."
        },
        {
            "ux_instruments": "The ITC - Sense of Presence Inventory (ITC-SOPI)",
            "reference": "Lessiter, Jane, et al. \"A cross-media presence questionnaire: The ITC-Sense of Presence Inventory.\" Presence: Teleoperators & Virtual Environments 10.3 (2001): 282-297.",
            "year": "2001",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "-",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Presence",
            "sub_qualities_or_valence": "(1) Sense of Physical Space, (2) Engagement, (3) Ecological Validity, and (4) Negative Effects",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "A cross-media presence measure that allows results from different laboratories to be compared and a more comprehensive knowledge base to be developed. It is a questionnaire with a 5-point Likert scale (1 - strongly disagree; 5 -strongly agree) where Sense o f Physical Space: 19 items;  Engagement: 13 items; Ecological Validity: 5 items; and Negative Effects: 6 items. ",
            "general_procedure": "The ITC-SOPI must be administered to people following an experience with a mediated environment. "
        },
        {
            "ux_instruments": "This-or-that",
            "reference": "Zaman, B. 2009. Introduction and validation of a pairwise comparison scale for UX evaluations and benchmarking with preschoolers. in Interact. Uppsala: Springer. and Sim, Gavin, and Matthew Horton. \"Investigating children's opinions of games: Fun Toolkit vs. This or That.\" Proceedings of the 11th International Conference on Interaction Design and Children. ACM, 2012.",
            "year": "2009",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "(1) challenge & control, (2) fantasy, (3) creative and constructive expressions, (4) social experiences, (5) body and senses",
            "target_users_": "Children",
            "framework": "Human/user focus ",
            "main_ideia": "It is a mixed-method approach to benchmark children’s user experiences with technologies ",
            "general_procedure": "the This-or-That method equates a within subject experiment consisting of four phases in which children are invited individually to judge preferences on user experiences of two technologies. During the first phase, children can explore both technologies. Secondly, a quantitative survey questionnaire (based on the UX scale) is verbally administered to let children judge preferences between both conditions. The answers are then validated qualitatively through a short probing interview. Finally, their preferences are also validated through a behavioural choice: at the end of the experiment, we allowed children to play one of the two conditions again as ‘a reward for good participation. "
        },
        {
            "ux_instruments": "Tracking Realtime User Experience (TRUE)",
            "reference": "KIM, Jun H. et al. Tracking real-time user experience (TRUE): a comprehensive instrumentation solution for complex systems. In: Proceedings of the SIGCHI conference on Human Factors in Computing Systems. ACM, 2008. p. 443-452.",
            "year": "2008",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Games and virtual environments",
            "ux-quality": "Aspects of game experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "Participants play a game and their behavior and reactions are recorded on logs and a video.",
            "general_procedure": "Games software is instrumented to track behavior, users report reactions throughout test, live video record is indexed to events."
        },
        {
            "ux_instruments": "Teste de Usabilidade de Tecnologia Assistiva- Formulário (TUTAForm)",
            "reference": "Sales, Angelina, et al. \"Tutaform: A Multimedia Form for Brazilian Deaf Users.\" Proceedings of the 24th Brazilian Symposium on Multimedia and the Web. ACM, 2018.",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "-",
            "application_domain": "Application-independent",
            "ux-quality": "Satisfaction",
            "sub_qualities_or_valence": "Satisfaction and emotional state ",
            "target_users_": "People with disabilities",
            "framework": "Human/user focus ",
            "main_ideia": "Consists of an online and multimedia form (video, images, animations) to assist in the collection of data from deaf users who participate in Usability Testing in the evaluation of Assistive Technology resources.",
            "general_procedure": "TUTAForm is a form which utilizes multimedia resources to present content in the Brazilian Sign Language (LIBRAS), to collect data about the satisfaction component from assistive technology usability. Consists of a 19-item scale, organized in three sections: profile, level of (in)satisfaction and emotional state."
        },
        {
            "ux_instruments": "User Experience Questionnaire Short Version* (UEQ Short Version*)",
            "reference": "Alberola, C., Walter, G., & Brau, H. (2018). Creation of a Short Version of the User Experience Questionnaire UEQ. i-Com, 17(1), 57–64. doi:10.1515/icom-2017-0032",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A quick and reliable questionnaire to measure the user experience with interactive products.",
            "general_procedure": "Experience reported in the article: In a first study with the short version, 47 students judged the user experience of different products known. Each student can choose between judging Amazon, Skype or Wikipedia with an online version of UEQ-S."
        },
        {
            "ux_instruments": "UFOS-V2",
            "reference": "Christophersen, T., Konradt, U. Development and validation of a formative and a reflective measure for the assessment of online store usability. Behavior & Information Technolgy 31, 9 (2012), 839-857.",
            "year": "2012",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Online plataform",
            "ux-quality": "Usability",
            "sub_qualities_or_valence": "Trust, asethetics, subjective price level, intention to buy, decision to buy, controls, user experience, product involvement and product category",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "A questionnaire that consists of a reflexive and formative measure for the usability evaluation of online stores, from the point of view of customers.",
            "general_procedure": "Experience reported in the article: participants were recruited (through posters and leaflets in public facilities, through local Internet portals and advertisements in the local newspaper) to be part of a laboratory experiment. The experiment was conducted using an online hypertext environment that included all the instructions, stores and measurements. During the procedure, an experimenter was present to help with questions that seldom occurred. The experiment was carried out in sessions, with up to five participants at a time."
        },
        {
            "ux_instruments": "Usability Metric for User Experience (UMUX)",
            "reference": "Lewis, J. R. (2018). Measuring Perceived Usability: The CSUQ, SUS, and UMUX. International Journal of Human–Computer Interaction, 1–9.",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Perceived usability",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "Get a measurement of perceived usability using 4 items",
            "general_procedure": "Have seven scale steps from 1 (strongly disagree) to 7 (strongly agree) with the item scores manipulated to obtain an overall score that ranges from 0 to 100"
        },
        {
            "ux_instruments": "Usability Metric for User Experience Lite (UMUX-Lite)",
            "reference": "Lewis, J. R., Utesch, B. S., & Maher, D. E. (2013). UMUX-LITE. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI ’13. doi:10.1145/2470654.2481287 ",
            "year": "2013",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Application-independent",
            "ux-quality": "Perceived usability",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "-",
            "main_ideia": "A two-item questionnaire based on the Usability Metric for User Experience",
            "general_procedure": "The UMUX-LITE items are “This system’s capabilities meet my requirements” and “This system is easy to use.” "
        },
        {
            "ux_instruments": "Usefulness, Satisfaction, and Ease of Use Questionnaire (USE)",
            "reference": "Gao, Meiyuzi, Philip Kortum, and Frederick Oswald. \"Psychometric Evaluation of the USE (Usefulness, Satisfaction, and Ease of use) Questionnaire for Reliability and Validity.\" Proceedings of the Human Factors and Ergonomics Society Annual Meeting. Vol. 62. No. 1. Sage CA: Los Angeles, CA: SAGE Publications, 2018.",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Usability",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "The Usefulness, Satisfaction, and Ease of Use Questionnaire (USE, Lund, 2001) measures the subjective usability of a product or service. It is a 30-item survey that examines four dimensions of usability: usefulness, ease of use, ease of learning, and satisfaction",
            "general_procedure": "Participants indicate their experience level on a five-point scale (low/medium low/medium/medium high/high) and then completed the USE."
        },
        {
            "ux_instruments": "User Engagement Scale",
            "reference": "H. L. O’Brien and E. G. Toms. The development and evaluation of asurvey to measure user engagement.Journal of the American Societyfor Information Science and Technology, 61(1):50–69, jan 2010.",
            "year": "2010",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Engagement",
            "sub_qualities_or_valence": "Perceived usability, aesthetics, focused attention, felt involvement, novelty and endurability",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A multidimensional scale that may be used to test the engagement of software applications",
            "general_procedure": "The scale was administered using a five-point scale with “strongly disagree” and “strongly agree” at the respective end points."
        },
        {
            "ux_instruments": "User Experience Questionnaire",
            "reference": "B. Laugwitz, T. Held, and M. Schrepp. Construction and Evaluationof a User Experience Questionnaire.  pages 63–76. Springer, Berlin,Heidelberg, nov 2008",
            "year": "2008",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "Attractiveness, perspicuity, efficiency, dependability, stimulation and novelty",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "A fast and reliable questionnaire to measure the User Experience of interactive products.",
            "general_procedure": "Experiment reported in the article: Participants had to go through a scenario that contained typical tasks that a sales representative needs to perform frequently during their daily work. Each task was motivated by a short story that explained the context of the task and why it is performed. The participant was received and guided to the test station; moderators presented themselves and collected basic demographic data; he received an overview of the test session and the intent of the test; he was then asked to complete the tasks described (he was instructed to think aloud during his attempt to meet them.) After the participant finished the last task, the screen was disconnected and the participant completed the User Experience Questionnaire ."
        },
        {
            "ux_instruments": "UUX-Posts",
            "reference": "Mendes, M. S., & Furtado, E. S. (2017). UUX-Posts. Proceedings of the 8th Latin American Conference on Human-Computer Interaction - CLIHC ’17.",
            "year": "2017",
            "type_of_instrument": "Software/equipment",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Online plataform",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Human/user focus",
            "main_ideia": "A tool for extracting, collecting and classifying posts from users of social systems.",
            "general_procedure": "The evaluator can decide whether to evaluate the Usability of the System, UX or both (UUX). In their evaluation, they can choose which extraction patterns to use: verbs, types of posts (criticisms, doubts, suggestions, compliments, etc.) or which facets (satisfaction, frustration, aesthetics, etc.) of UUX should be used; The evaluator can evaluate the online postings or decide to download a file (a csv worksheet) with the postings for later evaluation; The data collected refers to the information provided by the user in the SS, such as age, gender and location. UUXPosts does not collect images, and in posts with user names, the names are omitted, acquiring the {user} tag. Posts are collected from SS public profiles such as Twitter, Facebook, or similar. The tool provides automatic sorting and extraction of releases using the Boolean recovery model."
        },
        {
            "ux_instruments": "UX Curve",
            "reference": "KUJALA, Sari et al. UX Curve: A method for evaluating long-term user experience. Interacting with Computers, v. 23, n. 5, p. 473-483, 2011.",
            "year": "2011",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "(1) attractiveness (appeal) of the product, (2) ease of use, (3) utility ",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "This instrument aims at assisting users in retrospectively reporting how and why their experience with a product has changed over time. UX Curve method enables users and researchers to determine the quality of long-term user experience and the influences that improve user experience over time or cause it to deteriorate. The method provided rich qualitative data and we found that an improving trend of perceived attractiveness of mobile phones was related to user satisfaction and willingness to recommend their phone to friends. the proposed method can be used as a straightforward tool for understanding the reasons why user experience improves or worsens in long-term product use and how these reasons relate to customer loyalty.",
            "general_procedure": "There is a template so that users can draw themselves a curve describing how their experiences had evolved over time. The instruction given with the template was: ‘Please recall the moment when you began to use the product. Draw a curve describing how your relationship towards the product has changed from the first time you used it until today.’ Users are then asked to mark the reasons at their approximate locations on the curve. The template includes an empty two-dimensional graph area and lines for writing on and briefly describing the reasons for the changes in the curve.  The horizontal axis represents the time dimension from the beginning of use to the current moment and the vertical axis represents the intensity of the users’ experience. In the middle of the graph area there was a horizontal zero line dividing the area into a positive upper part and a negative lower part. The vertical axis was labeled accordingly with + and - signs."
        },
        {
            "ux_instruments": "UX Semantic Differential Scale",
            "reference": "Macedo V., Marcio Silva C. (2014) Building a Semantic Differential Scale as Tool for Assisting UX Evaluation with Home Appliances. In: Marcus A. (eds) Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience. DUXU 2014. Lecture Notes in Computer Science, vol 8517. Springer, Cham",
            "year": "2014",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quali-Quantitative",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Generic User Experience",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "A  semantic  differential scale,  composed of  39 adjectives  collected  specifically  for  the  user  experience  evaluation with home appliances.",
            "general_procedure": "This scale presents opposite adjectives in pairs, connected by a certain space (it can be a line, likert scale, or even a blank space), in which the user marks the level of approximation based on a determined idea. The tool here presented can be adapted for different home appliances categories and it allows &#10;application on different stages of usage,  such as pre, during and post interaction."
        },
        {
            "ux_instruments": "UXAmI Observer",
            "reference": "Ntoa, Stavroula, et al. \"UXAmI Observer: An Automated User Experience Evaluation Tool for Ambient Intelligence Environments.\" Proceedings of SAI Intelligent Systems Conference. Springer, Cham, 2018.",
            "year": "2018",
            "type_of_instrument": "Two-dimensional Diagrams/Graph area",
            "type_of_approach": "Quali-quantitative",
            "application_domain": "Intelligent Systems, Environments and Objects",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": "Adaptation insertion and adaptation rejection,  input error,  emotion and implicit interactions.",
            "target_users_": "all types of users",
            "framework": "Human/user focus ",
            "main_ideia": "XAmI Observer aims to support evaluators in carrying out user-based    evaluations,    be    them    laboratory    task-based experiments, in situ evaluations, or long-term experiments. In a nutshell, the tool aggregates data regarding user’s interaction with   systems   and   applications   in   AmI   environments   and presents them through multiple views, such as timelines, charts, and  diagrams.",
            "general_procedure": "In task-based experiments the evaluator has to define the tasks and participant characteristics, whereas long-term experiments can be unstructured, employing users that are already registered in the system (e.g., the inhabitants of an actual AmI environment). Furthermore, the evaluator can view a user session live and provide annotations for it, or review the recorded data and further process them after the experiment. The tool provides two views for an experiment:  (i) a view of each interaction session, named Timeline, and (ii) insights from the entire experiment, based on all the users that are involved in it throughout the experiment period."
        },
        {
            "ux_instruments": "Visual Aesthetics of Websites Inventory (VisAWI)",
            "reference": "Moshagen, M., & Thielsch, M. T. (2010). Facets of visual aesthetics. International Journal of Human-Computer Studies, 68(10), 689–709. doi:10.1016/j.ijhcs.2010.05.006",
            "year": "2010",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative ",
            "application_domain": "Online plataform",
            "ux-quality": "Aesthetics",
            "sub_qualities_or_valence": "Simplicity, diversity, colorfulness, craftmanship ",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "A sound measure of visual aesthetics of websites comprising facets of both practical and theoretical interest",
            "general_procedure": "After providing demographic background information, participants enter a screen splitted into two parts. The website to be evaluated must be  displayed in the lower panel. The upper panel randomly shows one item at a time. Thus, participants simultaneously viewed both, the website and the items."
        },
        {
            "ux_instruments": "VisUX Questionnaire",
            "reference": "Veeneklaas, J. N. VisUX: a framework of user experience within data visualizations. MS thesis. 2018.",
            "year": "2018",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Application-independent",
            "ux-quality": "Specific sets of UX qualities",
            "sub_qualities_or_valence": " ",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "VisUX is a questionnaire that is based on a framework for describing all aspects of a data visualization (as good as possible) that influence the experience of the user.",
            "general_procedure": "After using a system, the participant answers the questionnaire."
        },
        {
            "ux_instruments": "Website Analysis and Measurement Inventory (WAMMI)",
            "reference": "Kirakowski, Jurek, and Bozena Cierlik. \"Measuring the usability of web sites.\" Proceedings of the Human Factors and Ergonomics Society Annual Meeting. Vol. 42. No. 4. Sage CA: Los Angeles, CA: SAGE Publications, 1998. and http://www.wammi.com",
            "year": "1998",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Online plataform",
            "ux-quality": "Satisfaction",
            "sub_qualities_or_valence": "(1) Attractiveness, (2) Controllability, (3) Efficiency, (4) Helpfulness and (5) Learnability.",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus ",
            "main_ideia": "WAMMI measures user-satisfaction by asking visitors to your website to compare their expectations with what they actually experience on the website. It is based around a standarised 20-statement questionnaire and a unique international database. WAMMI's uniqueness lies in that visitor satisfaction for the site being evaluated is compared with values from our reference databases, which now contain data from over 320 surveys. I benchmark websites, portal or intranet against others to see if it scored a good or bad result. By tracking performance over time, it sees if the improvements made have given the desired results from visitors pespective.  By asking additional questions, important information about visitors profiles, purpose of visit and how the website can be improved is obtained and cross referenced with the WAMMI results. WAMMI is a scientific analytics service, iteratively developed using Psychometric techniques. ",
            "general_procedure": "Visitors to sites complete the standard WAMMI questionnaire plus any additional questions the owner care to ask. The WAMMI team will assist the selecting additional questions to suit the business needs. When there are sufficient responses, usually after about two weeks, the evaluation is terminated. Owner receive an electronic report within two working days. The report benchmarks how well your site performs. Visitor reactions to the site are compared with values in our reference database and are shown in the WAMMI profile results and the Global Usability Score (GUS). More detailed analysis can be made by statement analysis and from visitor feedback about the changes and improvements made. The questionnaire can be used to evaluate intranet, using testing and educational purposes."
        },
        {
            "reference": "Chiew, Thiam Kian, and Siti Salwa Salim. \"Webuse: Website usability evaluation tool.\" Malaysian Journal of Computer Science 16.1 (2003): 47-57.",
            "year": "2003",
            "type_of_instrument": "Scale / Questionnaire",
            "type_of_approach": "Quantitative",
            "application_domain": "Online plataform",
            "ux-quality": "Satisfaction",
            "sub_qualities_or_valence": "-",
            "target_users_": "all types of users",
            "framework": "Product/artifact focus",
            "main_ideia": "WEBUSE (WEBsite USability Evaluation Tool). Based on literature research, a 24-question evaluation questionnaire has been formulated. The questionnaire is implemented as a Webbased tool.",
            "general_procedure": "Visitors’ of a website can use it to evaluate the usability of the website.  The visitors’ responses to the questionnaire are analysed.  The results of the analysis show the good and bad usability aspects of the website.  Website designers and developers can improve their websites based on these results."
        }
    ]
}
